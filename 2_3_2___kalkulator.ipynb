{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapamawi/AI/blob/main/2_3_2___kalkulator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "NWV9y1M4i_3K"
      },
      "id": "NWV9y1M4i_3K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0794228",
      "metadata": {
        "id": "f0794228"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index-llms-openai llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kod instaluje dwie biblioteki Pythona przy użyciu menedżera pakietów pip:\n",
        "\n",
        "1. llama-index-llms-openai - zawiera interfejsy do komunikacji z modelami językowymi OpenAI\n",
        "2. llama-index - framework do budowania aplikacji wykorzystujących duże modele językowe\n",
        "\n",
        "Flaga -q (quiet) powoduje, że pip wyświetla tylko najważniejsze informacje podczas instalacji, pomijając szczegółowe logi procesu.\n",
        "\n",
        "Te biblioteki razem pozwalają na tworzenie aplikacji wykorzystujących modele językowe OpenAI do przetwarzania i generowania tekstu, a także indeksowania i wyszukiwania w dużych zbiorach danych tekstowych."
      ],
      "metadata": {
        "id": "BdMjH1cYy_bU"
      },
      "id": "BdMjH1cYy_bU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ac1778-0585-43c9-9dad-014d13d7460d",
      "metadata": {
        "id": "e8ac1778-0585-43c9-9dad-014d13d7460d"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.agent import ReActAgent\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core.tools import BaseTool, FunctionTool\n",
        "from google.colab import userdata\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod importuje niezbędne elementy do stworzenia agenta AI oraz konfiguracji dostępu do API:\n",
        "\n",
        "`from llama_index.core.agent import ReActAgent` - importuje klasę ReActAgent, która implementuje agenta AI wykorzystującego podejście ReAct (Reasoning and Acting)\n",
        "\n",
        "`from llama_index.llms.openai import OpenAI` - importuje klasę do komunikacji z modelami OpenAI\n",
        "\n",
        "`from llama_index.core.llms import ChatMessage` - importuje klasę reprezentującą wiadomości w konwersacji\n",
        "\n",
        "`from llama_index.core.tools import BaseTool, FunctionTool` - importuje narzędzia pozwalające agentowi wykonywać konkretne zadania:\n",
        "- BaseTool to bazowa klasa dla wszystkich narzędzi\n",
        "- FunctionTool pozwala przekształcić zwykłe funkcje w narzędzia dla agenta\n",
        "\n",
        "`from google.colab import userdata` i `import os` - umożliwiają dostęp do danych użytkownika w Google Colab oraz operacje na systemie plików"
      ],
      "metadata": {
        "id": "I6ROhbn0zg_h"
      },
      "id": "I6ROhbn0zg_h"
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "  model = \"gpt-4o-mini\""
      ],
      "metadata": {
        "id": "PBTifpOEkxfa"
      },
      "id": "PBTifpOEkxfa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = userdata.get('openaivision')"
      ],
      "metadata": {
        "id": "Az5VatmFrLZY"
      },
      "id": "Az5VatmFrLZY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "60ed8ac9-04fd-4deb-81a2-44cd8b4e2fd6",
      "metadata": {
        "id": "60ed8ac9-04fd-4deb-81a2-44cd8b4e2fd6"
      },
      "source": [
        "# Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26472aaf-1a12-49f9-9fe6-cbf41dd15f88",
      "metadata": {
        "id": "26472aaf-1a12-49f9-9fe6-cbf41dd15f88"
      },
      "outputs": [],
      "source": [
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers and returns the result integer\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten fragment kodu definiuje prostą funkcję mnożenia i przekształca ją w narzędzie, które będzie mógł używać agent AI:\n",
        "\n",
        "`def multiply(a: int, b: int) -> int:` - definicja funkcji z adnotacjami typów:\n",
        "- przyjmuje dwa argumenty typu całkowitego (int)\n",
        "- zwraca wynik również jako liczbę całkowitą\n",
        "- komentarz w potrójnych cudzysłowach (docstring) opisuje działanie funkcji\n",
        "\n",
        "`multiply_tool = FunctionTool.from_defaults(fn=multiply)` - tworzy narzędzie z funkcji multiply:\n",
        "- FunctionTool.from_defaults() automatycznie tworzy narzędzie na podstawie podanej funkcji\n",
        "- narzędzie będzie dostępne dla agenta do wykonywania operacji mnożenia\n",
        "\n",
        "Agent będzie mógł użyć tego narzędzia, gdy będzie potrzebował pomnożyć dwie liczby w trakcie wykonywania swoich zadań."
      ],
      "metadata": {
        "id": "KgnV6ZJqz4ei"
      },
      "id": "KgnV6ZJqz4ei"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df78ae85-bcf7-44c1-87ee-f301e646db20",
      "metadata": {
        "id": "df78ae85-bcf7-44c1-87ee-f301e646db20"
      },
      "outputs": [],
      "source": [
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and returns the result integer\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "add_tool = FunctionTool.from_defaults(fn=add)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten fragment jest analogiczny do poprzedniego, ale implementuje dodawanie zamiast mnożenia:\n",
        "\n",
        "`def add(a: int, b: int) -> int:` - definicja funkcji dodawania:\n",
        "- przyjmuje dwa argumenty całkowite\n",
        "- zwraca ich sumę jako liczbę całkowitą\n",
        "- docstring opisuje funkcjonalność\n",
        "\n",
        "`add_tool = FunctionTool.from_defaults(fn=add)` - przekształca funkcję add w narzędzie:\n",
        "- tworzy narzędzie, które agent będzie mógł wykorzystać do dodawania liczb\n",
        "- używa tej samej metody FunctionTool.from_defaults() co poprzednio\n",
        "\n",
        "W ten sposób agent otrzymuje dostęp do dwóch podstawowych operacji arytmetycznych: dodawania i mnożenia."
      ],
      "metadata": {
        "id": "H6hd8Hwnz44F"
      },
      "id": "H6hd8Hwnz44F"
    },
    {
      "cell_type": "markdown",
      "id": "8b6c519f-6d74-4251-b38e-b8395a96d43b",
      "metadata": {
        "id": "8b6c519f-6d74-4251-b38e-b8395a96d43b"
      },
      "source": [
        "# Query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab300f1-b054-46d9-b1c8-dbcd0d538e5a",
      "metadata": {
        "id": "7ab300f1-b054-46d9-b1c8-dbcd0d538e5a"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(model= CFG.model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta linia tworzy instancję modelu językowego:\n",
        "\n",
        "`llm = OpenAI(model=CFG.model)` - inicjalizuje model OpenAI:\n",
        "- używa modelu zdefiniowanego wcześniej w klasie CFG (gpt-4o-mini)\n",
        "- tworzy obiekt llm (language learning model), który będzie odpowiedzialny za przetwarzanie języka naturalnego\n",
        "- ten obiekt będzie używany przez agenta do rozumienia poleceń i generowania odpowiedzi\n",
        "\n",
        "Jest to kluczowy element konfiguracji, który łączy nasz kod z API OpenAI i umożliwia korzystanie z możliwości modelu językowego."
      ],
      "metadata": {
        "id": "iJzN5ZGQ6MHx"
      },
      "id": "iJzN5ZGQ6MHx"
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)"
      ],
      "metadata": {
        "id": "LF8K7CSbsNv0"
      },
      "id": "LF8K7CSbsNv0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta linia tworzy agenta AI z określonymi narzędziami i modelem językowym:\n",
        "\n",
        "`ReActAgent.from_tools()` - tworzy nowego agenta wykorzystującego metodologię ReAct (Reasoning and Acting):\n",
        "- `[multiply_tool, add_tool]` - lista narzędzi dostępnych dla agenta (w tym przypadku mnożenie i dodawanie)\n",
        "- `llm=llm` - przypisuje wcześniej skonfigurowany model językowy\n",
        "- `verbose=True` - włącza szczegółowe logowanie, dzięki czemu będziemy widzieć proces rozumowania agenta\n",
        "\n",
        "Ten agent będzie mógł:\n",
        "- interpretować polecenia w języku naturalnym\n",
        "- decydować, które narzędzie użyć\n",
        "- wykonywać operacje matematyczne\n",
        "- przedstawiać wyniki swoich działań"
      ],
      "metadata": {
        "id": "feRnfVHL6YGK"
      },
      "id": "feRnfVHL6YGK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad7964a5-a953-4a53-9865-6a0795cd2772",
      "metadata": {
        "id": "ad7964a5-a953-4a53-9865-6a0795cd2772",
        "outputId": "0c879232-4bf6-4a42-e2c4-6f07ac667782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: agent_worker:system_prompt\n",
            "\n",
            "Value: You are designed to help with a variety of tasks, from answering questions to providing summaries to other types of analyses.\n",
            "\n",
            "## Tools\n",
            "\n",
            "You have access to a wide variety of tools. You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
            "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
            "\n",
            "You have access to the following tools:\n",
            "{tool_desc}\n",
            "\n",
            "\n",
            "## Output Format\n",
            "\n",
            "Please answer in the same language as the question and use the following format:\n",
            "\n",
            "```\n",
            "Thought: The current language of the user is: (user's language). I need to use a tool to help me answer the question.\n",
            "Action: tool name (one of {tool_names}) if using a tool.\n",
            "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
            "```\n",
            "\n",
            "Please ALWAYS start with a Thought.\n",
            "\n",
            "NEVER surround your response with markdown code markers. You may use code markers within your response if you need to.\n",
            "\n",
            "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
            "\n",
            "If this format is used, the user will respond in the following format:\n",
            "\n",
            "```\n",
            "Observation: tool response\n",
            "```\n",
            "\n",
            "You should keep repeating the above format till you have enough information to answer the question without using any more tools. At that point, you MUST respond in one of the following two formats:\n",
            "\n",
            "```\n",
            "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: [your answer here (In the same language as the user's question)]\n",
            "```\n",
            "\n",
            "```\n",
            "Thought: I cannot answer the question with the provided tools.\n",
            "Answer: [your answer here (In the same language as the user's question)]\n",
            "```\n",
            "\n",
            "## Current Conversation\n",
            "\n",
            "Below is the current conversation consisting of interleaving human and assistant messages.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt_dict = agent.get_prompts()\n",
        "for k, v in prompt_dict.items():\n",
        "    print(f\"Prompt: {k}\\n\\nValue: {v.template}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod wyświetla szablony promptów używanych przez agenta:\n",
        "\n",
        "`prompt_dict = agent.get_prompts()` - pobiera słownik zawierający wszystkie szablony promptów agenta\n",
        "\n",
        "Pętla `for k, v in prompt_dict.items():` przechodzi przez wszystkie elementy słownika:\n",
        "- `k` to klucz (nazwa promptu)\n",
        "- `v` to obiekt promptu\n",
        "- `v.template` zawiera faktyczny tekst szablonu\n",
        "- `print(f\"Prompt: {k}\\n\\nValue: {v.template}\")` wyświetla nazwę każdego promptu i jego zawartość\n",
        "\n",
        "Dzięki temu możemy zobaczyć, jakie szablony instrukcji agent wykorzystuje do:\n",
        "- planowania działań\n",
        "- podejmowania decyzji\n",
        "- formatowania odpowiedzi\n",
        "- interakcji z narzędziami"
      ],
      "metadata": {
        "id": "FHs_I2Z96qZG"
      },
      "id": "FHs_I2Z96qZG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69bb1aa9-1ea3-4c88-a4f3-239b76392aa5",
      "metadata": {
        "id": "69bb1aa9-1ea3-4c88-a4f3-239b76392aa5",
        "outputId": "b4a24c7a-2937-432b-cbda-f30ae953f2ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step e0ce578b-c8ed-4411-b52b-372594c02600. Step input: Jaki jest wynik 20+(2*4)? Przelicz krok po kroku \n",
            "\u001b[1;3;38;5;200mThought: Użytkownik prosi o obliczenie wyrażenia 20 + (2 * 4) krok po kroku. Najpierw obliczę część mnożenia, a następnie dodam wynik do 20.\n",
            "Action: multiply\n",
            "Action Input: {'a': 2, 'b': 4}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 8\n",
            "\u001b[0m> Running step 6228fed3-7bfd-410c-bae1-e5bd25a940fe. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: Wynik mnożenia 2 * 4 to 8. Teraz dodam ten wynik do 20.\n",
            "Action: add\n",
            "Action Input: {'a': 20, 'b': 8}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 28\n",
            "\u001b[0m> Running step 7260049b-02b9-4eea-a665-20070e0a9108. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
            "Answer: Wynik wyrażenia 20 + (2 * 4) to 28.\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Jaki jest wynik 20+(2*4)? Przelicz krok po kroku \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.chat(\"What is the result of 20+(2*4)? Calculate step by step\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFNk3rJLx-e2",
        "outputId": "1f2b57de-a50f-4bff-eebf-de3a1315a09d"
      },
      "id": "mFNk3rJLx-e2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Running step a0f09c69-d4b4-4099-a1bc-3a52e0af2ab6. Step input: What is the result of 20+(2*4)? Calculate step by step\n",
            "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
            "Action: multiply\n",
            "Action Input: {'a': 2, 'b': 4}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 8\n",
            "\u001b[0m> Running step a6074bba-5126-4aea-bd22-191e83e31647. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: Now that I have the result of the multiplication, I can proceed to add it to 20.\n",
            "Action: add\n",
            "Action Input: {'a': 20, 'b': 8}\n",
            "\u001b[0m\u001b[1;3;34mObservation: 28\n",
            "\u001b[0m> Running step 9e8d1f01-ec72-4804-abba-fd3eba534d59. Step input: None\n",
            "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
            "Answer: The result of 20 + (2 * 4) is 28.\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llama_index_v2",
      "language": "python",
      "name": "llama_index_v2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}