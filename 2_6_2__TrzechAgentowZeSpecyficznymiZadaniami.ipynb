{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapamawi/AI/blob/main/2_6_2__TrzechAgentowZeSpecyficznymiZadaniami.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "4s6a3CT33Q5P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVxjgnab3LlF",
        "outputId": "92fd7e05-fc18-4996-e7ac-1488b7f2f4f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.7/160.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.0/162.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.7/481.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.4/256.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.0/361.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.6/249.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.9/78.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.3 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.27.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29 openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod instaluje kilka bibliotek Pythona za pomocą menedżera pakietów pip:\n",
        "\n",
        "`crewai` w wersji 0.28.8 - biblioteka służąca do tworzenia i zarządzania zespołami agentów AI\n",
        "\n",
        "`crewai_tools` w wersji 0.1.6 - zestaw narzędzi rozszerzających funkcjonalność biblioteki crewai\n",
        "\n",
        "`langchain_community` w wersji 0.0.29 - biblioteka zawierająca komponenty do budowania aplikacji opartych na modelach językowych\n",
        "\n",
        "`openai` - oficjalny pakiet OpenAI umożliwiający integrację z ich modelami AI\n",
        "\n",
        "Flaga `-q` oznacza tryb \"quiet\" (cichy), który ogranicza wyświetlanie komunikatów podczas instalacji.\n",
        "\n",
        "Flaga `-U` (lub `--upgrade`) oznacza, że jeśli któraś z tych bibliotek jest już zainstalowana, zostanie zaktualizowana do podanej wersji."
      ],
      "metadata": {
        "id": "OkREgKYp5MmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import pandas as pd\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.agents import Tool\n",
        "from google.colab import userdata\n",
        "import json\n",
        "from pprint import pp as ppr"
      ],
      "metadata": {
        "id": "8x3gkXJQ5OHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod importuje niezbędne biblioteki i komponenty:\n",
        "\n",
        "`os` - moduł dostarczający funkcje do interakcji z systemem operacyjnym\n",
        "\n",
        "Z biblioteki `crewai` importowane są cztery główne klasy:\n",
        "- `Agent` - do tworzenia agentów AI\n",
        "- `Task` - do definiowania zadań\n",
        "- `Crew` - do organizowania zespołów agentów\n",
        "- `Process` - do zarządzania procesami\n",
        "\n",
        "`OpenAI` - klasa klienta API OpenAI służąca do komunikacji z modelami OpenAI\n",
        "\n",
        "`time` - moduł zawierający funkcje związane z czasem\n",
        "\n",
        "`pandas` (jako `pd`) - biblioteka do analizy i manipulacji danymi\n",
        "\n",
        "Z pakietu `langchain_community.document_loaders` importowany jest `CSVLoader` - narzędzie do wczytywania plików CSV\n",
        "\n",
        "Z `langchain.agents` importowana jest klasa `Tool` służąca do tworzenia narzędzi dla agentów\n",
        "\n",
        "`userdata` z `google.colab` pozwala na dostęp do danych użytkownika w środowisku Google Colab"
      ],
      "metadata": {
        "id": "1UR7ztYG5PxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    model = 'gpt-4o-mini'"
      ],
      "metadata": {
        "id": "S8q-S0NW5RnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openaivision')\n"
      ],
      "metadata": {
        "id": "UF0zFiOn5TGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dane"
      ],
      "metadata": {
        "id": "Ny-2z4wM5-ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/telecom_churn.csv')\n",
        "df[['Churn', 'AccountWeeks', 'DataUsage','ContractRenewal', 'RoamMins']].sample(100).reset_index(drop = True).to_csv('sub_telecom_churn.csv', index = False)"
      ],
      "metadata": {
        "id": "2kUyaAWT5_Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod wykonuje kilka operacji na ramce danych (DataFrame) o nazwie `df`:\n",
        "\n",
        "1. Wybiera tylko określone kolumny z danych:\n",
        "   - `Churn` (odejścia klientów)\n",
        "   - `AccountWeeks` (liczba tygodni posiadania konta)\n",
        "   - `DataUsage` (zużycie danych)\n",
        "   - `ContractRenewal` (odnowienie umowy)\n",
        "   - `RoamMins` (minuty w roamingu)\n",
        "\n",
        "2. Za pomocą `sample(100)` losowo wybiera 100 wierszy z tych danych\n",
        "\n",
        "3. `reset_index(drop = True)` resetuje indeksy wybranych wierszy, a parametr `drop = True` usuwa starą kolumnę indeksów\n",
        "\n",
        "4. `to_csv('sub_telecom_churn.csv', index = False)` zapisuje wynikowe dane do pliku CSV o nazwie 'sub_telecom_churn.csv'. Parametr `index = False` oznacza, że indeksy wierszy nie zostaną zapisane w pliku\n",
        "\n",
        "Jest to typowa operacja przygotowania mniejszego zbioru danych do testów lub analizy, w tym przypadku z danych telekomunikacyjnych dotyczących odejść klientów."
      ],
      "metadata": {
        "id": "j3zJvhx46l4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentura"
      ],
      "metadata": {
        "id": "M0nJv6u06wQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tool = data loader\n",
        "loader = CSVLoader(file_path=\"sub_telecom_churn.csv\")\n",
        "\n",
        "load_tool = Tool(\n",
        "  name=\"Data Loader Tool\",\n",
        "  func=loader.load,\n",
        "  description=\"Load the CSV data from the source\",\n",
        ")"
      ],
      "metadata": {
        "id": "fvduAfVA64tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten fragment kodu tworzy narzędzie do wczytywania danych:\n",
        "\n",
        "`loader = CSVLoader(file_path=\"sub_telecom_churn.csv\")` - tworzy obiekt do wczytywania danych z pliku CSV 'sub_telecom_churn.csv'\n",
        "\n",
        "Następnie definiowane jest narzędzie `load_tool` za pomocą klasy `Tool` z trzema parametrami:\n",
        "- `name` - nazwa narzędzia: \"Data Loader Tool\"\n",
        "- `func` - funkcja wykonywana przez narzędzie: `loader.load` (wczytywanie danych)\n",
        "- `description` - opis działania narzędzia: \"Load the CSV data from the source\"\n",
        "\n",
        "To narzędzie będzie używane przez agentów AI do wczytywania i analizowania danych z pliku CSV."
      ],
      "metadata": {
        "id": "Ikbtr7J865C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your agents with roles and goals\n",
        "analyst = Agent(\n",
        "  role='Senior Data Analyst',\n",
        "  goal='Load the dataset and provide insights from the data',\n",
        "  backstory=\"\"\"You work at a telecom company.\n",
        "  Your expertise lies in identifying trends and analysis from the available data.\n",
        "  You have a knack for dissecting complex data and presenting\n",
        "  actionable insights.\"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        "  tools=[load_tool]\n",
        ")\n",
        "\n",
        "data_scientist = Agent(\n",
        "  role='Senior Data Scientist',\n",
        "  goal='Develop the best machine learning model according to intended goal',\n",
        "  backstory=\"\"\"You are a renowned data scientist, known for\n",
        "  your highly inonvative machine learning model with Python.\n",
        "  You transform the data into something the machine learning model could \\\n",
        "  accept and develop machine learning model based on it.\"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        ")\n",
        "\n",
        "machine_learning_engineer = Agent(\n",
        "  role='Senior Machine Learning Engineer',\n",
        "  goal='Create the best code to deploy the machine learning model',\n",
        "  backstory=\"\"\"You are an experienced machine learning engineer, having \\\n",
        "  lot of experience to deploy machine learning model.\n",
        "  You do your best to deploy the model based on the provided code\"\"\",\n",
        "  verbose=True,\n",
        "  allow_delegation=False,\n",
        ")"
      ],
      "metadata": {
        "id": "t5SYW5t26xGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod definiuje trzech agentów AI ze specyficznymi rolami:\n",
        "\n",
        "`analyst` - Starszy Analityk Danych:\n",
        "- Cel: wczytanie i analiza danych\n",
        "- Historia: pracownik firmy telekomunikacyjnej, ekspert w identyfikacji trendów i analizie danych\n",
        "- Ma dostęp do narzędzia `load_tool` do wczytywania danych\n",
        "\n",
        "`data_scientist` - Starszy Naukowiec Danych:\n",
        "- Cel: stworzenie najlepszego modelu uczenia maszynowego\n",
        "- Historia: znany naukowiec, specjalizuje się w innowacyjnych modelach uczenia maszynowego w Pythonie\n",
        "- Umiejętności: przekształcanie danych pod kątem wykorzystania w modelach ML\n",
        "\n",
        "`machine_learning_engineer` - Starszy Inżynier ML:\n",
        "- Cel: stworzenie kodu do wdrożenia modelu uczenia maszynowego\n",
        "- Historia: doświadczony inżynier specjalizujący się we wdrażaniu modeli ML\n",
        "- Skupia się na praktycznym wdrożeniu modelu\n",
        "\n",
        "Wszyscy agenci mają:\n",
        "- `verbose=True` - pokazują szczegóły swoich działań\n",
        "- `allow_delegation=False` - nie mogą delegować zadań"
      ],
      "metadata": {
        "id": "WyaUnOJ97cUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task1 = Task(\n",
        "  description=\"\"\"Conduct a comprehensive analysis from the CSV dataset \\\n",
        "  by using the tools provided.\n",
        "  You only need to run the tools and without providing any 'tool_input', as \\\n",
        "  the tools already have the source data path embedded to it.\n",
        "  Identify any analysis that related to why churn is happening. \"\"\",\n",
        "  agent=analyst,\n",
        "  expected_output = \"Full analysis report\"\n",
        ")\n",
        "\n",
        "task2 = Task(\n",
        "  description=\"\"\"Using the insights provided, develop a machine learning \\\n",
        "  model to predict the Churn.\n",
        "  The model should follow machine learning best practice, especially from \\\n",
        "  preprocessing to validation.\n",
        "  Your Final answer must be the full python code, only the python code and nothing else.\n",
        "  \"\"\",\n",
        "  agent=data_scientist,\n",
        "  expected_output = \"Python code of the machine learning model to predict churn\"\n",
        ")\n",
        "\n",
        "task3 = Task(\n",
        "  description=\"\"\"From the code you get, develop a Python code to deploy \\\n",
        "  the machine learning model in the production application.\n",
        "  The model deployment should follow the best practice.\n",
        "  The model object should be the output.\n",
        "  Start simple, and iterate if it is required.\n",
        "  Your Final answer must be the full python code from the machine \\\n",
        "  learning development to the model deploying, only the python code and nothing else.\n",
        "  \"\"\",\n",
        "  agent=machine_learning_engineer,\n",
        "  expected_output = \"Python code to deploy the machine learning model\",\n",
        "  context = [task2]\n",
        ")"
      ],
      "metadata": {
        "id": "K3AueYQV7hHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod definiuje trzy zadania dla wcześniej utworzonych agentów:\n",
        "\n",
        "`task1` - zadanie dla analityka:\n",
        "- Przeprowadzenie kompleksowej analizy danych z pliku CSV\n",
        "- Nie wymaga dodatkowych parametrów wejściowych dla narzędzi\n",
        "- Identyfikacja przyczyn rezygnacji klientów (churn)\n",
        "- Oczekiwany wynik: pełny raport z analizy\n",
        "\n",
        "`task2` - zadanie dla naukowca danych:\n",
        "- Stworzenie modelu ML do przewidywania rezygnacji klientów\n",
        "- Model ma być zgodny z najlepszymi praktykami (od przetwarzania wstępnego po walidację)\n",
        "- Oczekiwany wynik: kompletny kod w Pythonie dla modelu ML\n",
        "\n",
        "`task3` - zadanie dla inżyniera ML:\n",
        "- Stworzenie kodu do wdrożenia modelu ML w aplikacji produkcyjnej\n",
        "- Wdrożenie zgodne z najlepszymi praktykami\n",
        "- Wynikiem ma być obiekt modelu\n",
        "- Podejście iteracyjne, zaczynając od prostego rozwiązania\n",
        "- Wymaga kontekstu z zadania 2 (`context = [task2]`)\n",
        "- Oczekiwany wynik: pełny kod w Pythonie od rozwoju do wdrożenia modelu ML"
      ],
      "metadata": {
        "id": "tkM1jTuX771_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "  agents=[analyst, data_scientist, machine_learning_engineer ],\n",
        "  tasks=[task1, task2, task3],\n",
        "  verbose=2,\n",
        ")\n",
        "\n",
        "result = crew.kickoff()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-x7pxLT7-Vg",
        "outputId": "9650c819-bc2a-4588-c8b6-a47e142106e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Senior Data Analyst\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Conduct a comprehensive analysis from the CSV dataset   by using the tools provided.\n",
            "  You only need to run the tools and without providing any 'tool_input', as   the tools already have the source data path embedded to it.\n",
            "  Identify any analysis that related to why churn is happening. \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to load the CSV data from the source to understand and analyze the churn rate in the telecom company.\n",
            "\n",
            "Action: Data Loader Tool\n",
            "\n",
            "Action Input: {}\n",
            "\u001b[0m\u001b[95m \n",
            "\n",
            "[Document(page_content='Churn: 0\\nAccountWeeks: 56\\nDataUsage: 0.0\\nContractRenewal: 0\\nRoamMins: 10.5', metadata={'source': 'sub_telecom_churn.csv', 'row': 0}), Document(page_content='Churn: 0\\nAccountWeeks: 45\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 9.0', metadata={'source': 'sub_telecom_churn.csv', 'row': 1}), Document(page_content='Churn: 0\\nAccountWeeks: 102\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 11.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 2}), Document(page_content='Churn: 0\\nAccountWeeks: 171\\nDataUsage: 0.31\\nContractRenewal: 1\\nRoamMins: 13.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 3}), Document(page_content='Churn: 0\\nAccountWeeks: 200\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 11.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 4}), Document(page_content='Churn: 0\\nAccountWeeks: 123\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 13.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 5}), Document(page_content='Churn: 0\\nAccountWeeks: 82\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 9.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 6}), Document(page_content='Churn: 0\\nAccountWeeks: 119\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 11.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 7}), Document(page_content='Churn: 0\\nAccountWeeks: 149\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 9.7', metadata={'source': 'sub_telecom_churn.csv', 'row': 8}), Document(page_content='Churn: 0\\nAccountWeeks: 100\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 12.5', metadata={'source': 'sub_telecom_churn.csv', 'row': 9}), Document(page_content='Churn: 1\\nAccountWeeks: 115\\nDataUsage: 0.0\\nContractRenewal: 0\\nRoamMins: 10.8', metadata={'source': 'sub_telecom_churn.csv', 'row': 10}), Document(page_content='Churn: 0\\nAccountWeeks: 115\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 9.6', metadata={'source': 'sub_telecom_churn.csv', 'row': 11}), Document(page_content='Churn: 0\\nAccountWeeks: 142\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 14.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 12}), Document(page_content='Churn: 0\\nAccountWeeks: 99\\nDataUsage: 1.97\\nContractRenewal: 1\\nRoamMins: 7.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 13}), Document(page_content='Churn: 0\\nAccountWeeks: 45\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 12.4', metadata={'source': 'sub_telecom_churn.csv', 'row': 14}), Document(page_content='Churn: 0\\nAccountWeeks: 114\\nDataUsage: 2.78\\nContractRenewal: 1\\nRoamMins: 10.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 15}), Document(page_content='Churn: 0\\nAccountWeeks: 112\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 6.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 16}), Document(page_content='Churn: 0\\nAccountWeeks: 94\\nDataUsage: 0.22\\nContractRenewal: 1\\nRoamMins: 13.4', metadata={'source': 'sub_telecom_churn.csv', 'row': 17}), Document(page_content='Churn: 0\\nAccountWeeks: 100\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 4.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 18}), Document(page_content='Churn: 0\\nAccountWeeks: 122\\nDataUsage: 3.19\\nContractRenewal: 1\\nRoamMins: 11.8', metadata={'source': 'sub_telecom_churn.csv', 'row': 19}), Document(page_content='Churn: 0\\nAccountWeeks: 73\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 5.9', metadata={'source': 'sub_telecom_churn.csv', 'row': 20}), Document(page_content='Churn: 0\\nAccountWeeks: 126\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 7.8', metadata={'source': 'sub_telecom_churn.csv', 'row': 21}), Document(page_content='Churn: 0\\nAccountWeeks: 136\\nDataUsage: 0.0\\nContractRenewal: 0\\nRoamMins: 9.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 22}), Document(page_content='Churn: 0\\nAccountWeeks: 109\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 8.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 23}), Document(page_content='Churn: 0\\nAccountWeeks: 27\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 15.0', metadata={'source': 'sub_telecom_churn.csv', 'row': 24}), Document(page_content='Churn: 0\\nAccountWeeks: 157\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 7.9', metadata={'source': 'sub_telecom_churn.csv', 'row': 25}), Document(page_content='Churn: 0\\nAccountWeeks: 75\\nDataUsage: 3.02\\nContractRenewal: 1\\nRoamMins: 11.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 26}), Document(page_content='Churn: 0\\nAccountWeeks: 44\\nDataUsage: 0.32\\nContractRenewal: 1\\nRoamMins: 7.6', metadata={'source': 'sub_telecom_churn.csv', 'row': 27}), Document(page_content='Churn: 0\\nAccountWeeks: 121\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 11.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 28}), Document(page_content='Churn: 0\\nAccountWeeks: 164\\nDataUsage: 3.56\\nContractRenewal: 1\\nRoamMins: 13.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 29}), Document(page_content='Churn: 0\\nAccountWeeks: 122\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 11.9', metadata={'source': 'sub_telecom_churn.csv', 'row': 30}), Document(page_content='Churn: 0\\nAccountWeeks: 83\\nDataUsage: 3.59\\nContractRenewal: 1\\nRoamMins: 13.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 31}), Document(page_content='Churn: 0\\nAccountWeeks: 101\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 13.9', metadata={'source': 'sub_telecom_churn.csv', 'row': 32}), Document(page_content='Churn: 0\\nAccountWeeks: 56\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 14.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 33}), Document(page_content='Churn: 1\\nAccountWeeks: 77\\nDataUsage: 4.13\\nContractRenewal: 1\\nRoamMins: 15.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 34}), Document(page_content='Churn: 0\\nAccountWeeks: 98\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 8.5', metadata={'source': 'sub_telecom_churn.csv', 'row': 35}), Document(page_content='Churn: 0\\nAccountWeeks: 89\\nDataUsage: 0.15\\nContractRenewal: 1\\nRoamMins: 6.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 36}), Document(page_content='Churn: 0\\nAccountWeeks: 115\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 14.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 37}), Document(page_content='Churn: 0\\nAccountWeeks: 128\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 18.9', metadata={'source': 'sub_telecom_churn.csv', 'row': 38}), Document(page_content='Churn: 0\\nAccountWeeks: 109\\nDataUsage: 2.51\\nContractRenewal: 0\\nRoamMins: 9.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 39}), Document(page_content='Churn: 0\\nAccountWeeks: 108\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 9.4', metadata={'source': 'sub_telecom_churn.csv', 'row': 40}), Document(page_content='Churn: 1\\nAccountWeeks: 40\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 11.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 41}), Document(page_content='Churn: 0\\nAccountWeeks: 93\\nDataUsage: 2.65\\nContractRenewal: 1\\nRoamMins: 9.8', metadata={'source': 'sub_telecom_churn.csv', 'row': 42}), Document(page_content='Churn: 0\\nAccountWeeks: 92\\nDataUsage: 2.7\\nContractRenewal: 1\\nRoamMins: 10.0', metadata={'source': 'sub_telecom_churn.csv', 'row': 43}), Document(page_content='Churn: 1\\nAccountWeeks: 136\\nDataUsage: 0.0\\nContractRenewal: 0\\nRoamMins: 11.0', metadata={'source': 'sub_telecom_churn.csv', 'row': 44}), Document(page_content='Churn: 0\\nAccountWeeks: 146\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 12.6', metadata={'source': 'sub_telecom_churn.csv', 'row': 45}), Document(page_content='Churn: 0\\nAccountWeeks: 158\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 8.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 46}), Document(page_content='Churn: 0\\nAccountWeeks: 157\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 10.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 47}), Document(page_content='Churn: 0\\nAccountWeeks: 99\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 6.0', metadata={'source': 'sub_telecom_churn.csv', 'row': 48}), Document(page_content='Churn: 1\\nAccountWeeks: 118\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 14.4', metadata={'source': 'sub_telecom_churn.csv', 'row': 49}), Document(page_content='Churn: 1\\nAccountWeeks: 56\\nDataUsage: 0.16\\nContractRenewal: 1\\nRoamMins: 14.8', metadata={'source': 'sub_telecom_churn.csv', 'row': 50}), Document(page_content='Churn: 0\\nAccountWeeks: 132\\nDataUsage: 2.32\\nContractRenewal: 1\\nRoamMins: 8.6', metadata={'source': 'sub_telecom_churn.csv', 'row': 51}), Document(page_content='Churn: 1\\nAccountWeeks: 74\\nDataUsage: 0.21\\nContractRenewal: 1\\nRoamMins: 9.4', metadata={'source': 'sub_telecom_churn.csv', 'row': 52}), Document(page_content='Churn: 0\\nAccountWeeks: 64\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 9.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 53}), Document(page_content='Churn: 0\\nAccountWeeks: 74\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 9.7', metadata={'source': 'sub_telecom_churn.csv', 'row': 54}), Document(page_content='Churn: 1\\nAccountWeeks: 162\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 9.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 55}), Document(page_content='Churn: 1\\nAccountWeeks: 73\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 10.7', metadata={'source': 'sub_telecom_churn.csv', 'row': 56}), Document(page_content='Churn: 1\\nAccountWeeks: 147\\nDataUsage: 2.73\\nContractRenewal: 1\\nRoamMins: 10.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 57}), Document(page_content='Churn: 0\\nAccountWeeks: 136\\nDataUsage: 0.0\\nContractRenewal: 0\\nRoamMins: 10.4', metadata={'source': 'sub_telecom_churn.csv', 'row': 58}), Document(page_content='Churn: 0\\nAccountWeeks: 73\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 15.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 59}), Document(page_content='Churn: 0\\nAccountWeeks: 80\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 5.5', metadata={'source': 'sub_telecom_churn.csv', 'row': 60}), Document(page_content='Churn: 0\\nAccountWeeks: 168\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 11.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 61}), Document(page_content='Churn: 0\\nAccountWeeks: 32\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 14.8', metadata={'source': 'sub_telecom_churn.csv', 'row': 62}), Document(page_content='Churn: 0\\nAccountWeeks: 41\\nDataUsage: 0.34\\nContractRenewal: 1\\nRoamMins: 9.6', metadata={'source': 'sub_telecom_churn.csv', 'row': 63}), Document(page_content='Churn: 0\\nAccountWeeks: 193\\nDataUsage: 3.32\\nContractRenewal: 1\\nRoamMins: 12.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 64}), Document(page_content='Churn: 0\\nAccountWeeks: 81\\nDataUsage: 3.29\\nContractRenewal: 1\\nRoamMins: 12.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 65}), Document(page_content='Churn: 1\\nAccountWeeks: 78\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 7.9', metadata={'source': 'sub_telecom_churn.csv', 'row': 66}), Document(page_content='Churn: 0\\nAccountWeeks: 35\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 5.8', metadata={'source': 'sub_telecom_churn.csv', 'row': 67}), Document(page_content='Churn: 1\\nAccountWeeks: 77\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 9.8', metadata={'source': 'sub_telecom_churn.csv', 'row': 68}), Document(page_content='Churn: 0\\nAccountWeeks: 85\\nDataUsage: 0.38\\nContractRenewal: 0\\nRoamMins: 8.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 69}), Document(page_content='Churn: 0\\nAccountWeeks: 96\\nDataUsage: 3.05\\nContractRenewal: 1\\nRoamMins: 11.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 70}), Document(page_content='Churn: 0\\nAccountWeeks: 61\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 7.0', metadata={'source': 'sub_telecom_churn.csv', 'row': 71}), Document(page_content='Churn: 1\\nAccountWeeks: 64\\nDataUsage: 0.18\\nContractRenewal: 0\\nRoamMins: 13.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 72}), Document(page_content='Churn: 0\\nAccountWeeks: 127\\nDataUsage: 2.75\\nContractRenewal: 1\\nRoamMins: 10.2', metadata={'source': 'sub_telecom_churn.csv', 'row': 73}), Document(page_content='Churn: 0\\nAccountWeeks: 112\\nDataUsage: 2.62\\nContractRenewal: 1\\nRoamMins: 9.7', metadata={'source': 'sub_telecom_churn.csv', 'row': 74}), Document(page_content='Churn: 0\\nAccountWeeks: 35\\nDataUsage: 0.32\\nContractRenewal: 1\\nRoamMins: 8.9', metadata={'source': 'sub_telecom_churn.csv', 'row': 75}), Document(page_content='Churn: 0\\nAccountWeeks: 91\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 11.6', metadata={'source': 'sub_telecom_churn.csv', 'row': 76}), Document(page_content='Churn: 0\\nAccountWeeks: 117\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 10.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 77}), Document(page_content='Churn: 0\\nAccountWeeks: 78\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 14.0', metadata={'source': 'sub_telecom_churn.csv', 'row': 78}), Document(page_content='Churn: 0\\nAccountWeeks: 125\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 8.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 79}), Document(page_content='Churn: 0\\nAccountWeeks: 77\\nDataUsage: 1.92\\nContractRenewal: 1\\nRoamMins: 7.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 80}), Document(page_content='Churn: 0\\nAccountWeeks: 93\\nDataUsage: 0.24\\nContractRenewal: 1\\nRoamMins: 10.9', metadata={'source': 'sub_telecom_churn.csv', 'row': 81}), Document(page_content='Churn: 0\\nAccountWeeks: 166\\nDataUsage: 2.38\\nContractRenewal: 0\\nRoamMins: 8.8', metadata={'source': 'sub_telecom_churn.csv', 'row': 82}), Document(page_content='Churn: 0\\nAccountWeeks: 195\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 5.1', metadata={'source': 'sub_telecom_churn.csv', 'row': 83}), Document(page_content='Churn: 0\\nAccountWeeks: 99\\nDataUsage: 2.27\\nContractRenewal: 0\\nRoamMins: 8.4', metadata={'source': 'sub_telecom_churn.csv', 'row': 84}), Document(page_content='Churn: 0\\nAccountWeeks: 111\\nDataUsage: 0.25\\nContractRenewal: 1\\nRoamMins: 6.4', metadata={'source': 'sub_telecom_churn.csv', 'row': 85}), Document(page_content='Churn: 0\\nAccountWeeks: 128\\nDataUsage: 0.0\\nContractRenewal: 0\\nRoamMins: 10.7', metadata={'source': 'sub_telecom_churn.csv', 'row': 86}), Document(page_content='Churn: 1\\nAccountWeeks: 72\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 5.0', metadata={'source': 'sub_telecom_churn.csv', 'row': 87}), Document(page_content='Churn: 0\\nAccountWeeks: 76\\nDataUsage: 0.38\\nContractRenewal: 1\\nRoamMins: 9.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 88}), Document(page_content='Churn: 0\\nAccountWeeks: 59\\nDataUsage: 0.28\\nContractRenewal: 1\\nRoamMins: 5.0', metadata={'source': 'sub_telecom_churn.csv', 'row': 89}), Document(page_content='Churn: 0\\nAccountWeeks: 94\\nDataUsage: 0.0\\nContractRenewal: 0\\nRoamMins: 8.7', metadata={'source': 'sub_telecom_churn.csv', 'row': 90}), Document(page_content='Churn: 1\\nAccountWeeks: 123\\nDataUsage: 0.0\\nContractRenewal: 0\\nRoamMins: 6.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 91}), Document(page_content='Churn: 0\\nAccountWeeks: 121\\nDataUsage: 2.59\\nContractRenewal: 1\\nRoamMins: 9.6', metadata={'source': 'sub_telecom_churn.csv', 'row': 92}), Document(page_content='Churn: 0\\nAccountWeeks: 153\\nDataUsage: 2.54\\nContractRenewal: 1\\nRoamMins: 9.4', metadata={'source': 'sub_telecom_churn.csv', 'row': 93}), Document(page_content='Churn: 0\\nAccountWeeks: 115\\nDataUsage: 1.51\\nContractRenewal: 1\\nRoamMins: 5.6', metadata={'source': 'sub_telecom_churn.csv', 'row': 94}), Document(page_content='Churn: 0\\nAccountWeeks: 92\\nDataUsage: 0.25\\nContractRenewal: 1\\nRoamMins: 10.8', metadata={'source': 'sub_telecom_churn.csv', 'row': 95}), Document(page_content='Churn: 0\\nAccountWeeks: 147\\nDataUsage: 0.25\\nContractRenewal: 1\\nRoamMins: 14.4', metadata={'source': 'sub_telecom_churn.csv', 'row': 96}), Document(page_content='Churn: 1\\nAccountWeeks: 132\\nDataUsage: 2.84\\nContractRenewal: 1\\nRoamMins: 10.5', metadata={'source': 'sub_telecom_churn.csv', 'row': 97}), Document(page_content='Churn: 0\\nAccountWeeks: 177\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 14.6', metadata={'source': 'sub_telecom_churn.csv', 'row': 98}), Document(page_content='Churn: 0\\nAccountWeeks: 130\\nDataUsage: 0.0\\nContractRenewal: 1\\nRoamMins: 6.3', metadata={'source': 'sub_telecom_churn.csv', 'row': 99})]\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: \n",
            "Based on the data loaded, there are several factors that might be contributing to customer churn such as the length of account (AccountWeeks), data usage (DataUsage), whether or not they have renewed their contract (ContractRenewal), and the number of roaming minutes (RoamMins). \n",
            "\n",
            "Now I will analyze these factors to see if there are any patterns or trends that can provide insight into why churn is occurring.\n",
            "\n",
            "Action: Data Loader Tool\n",
            "\n",
            "Action Input: {}\n",
            "\u001b[0m\u001b[95m \n",
            "\n",
            "I tried reusing the same input, I must stop using this action input. I'll try something else instead.\n",
            "\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[32;1m\u001b[1;3mThought: \n",
            "I have all the data I need from the previous action. Now I will analyze this data.\n",
            "\n",
            "Final Answer: \n",
            "1. AccountWeeks: The length of the customer's account varies across the data with the range of 27 to 200 weeks. There doesn't seem to be a direct correlation between the length of the account and customer churn based on the data provided. Both customers with short and long account lengths have churned.\n",
            "\n",
            "2. DataUsage: The data usage also varies across the data, ranging from 0.0 to 4.13. Interestingly, customers with 0 data usage have both churned and not churned. However, there is a slight trend that customers with higher data usage tend to not churn, suggesting that customers who utilize more services are less likely to churn.\n",
            "\n",
            "3. ContractRenewal: Most of the customers in the data have renewed their contract (ContractRenewal = 1). However, there are also customers who have not renewed their contracts and have churned. This suggests that customers who do not renew their contracts are more likely to churn.\n",
            "\n",
            "4. RoamMins: There does not seem to be a clear trend between the number of roaming minutes and customer churn. Customers with various amounts of roaming minutes have both churned and not churned.\n",
            "\n",
            "Overall, the data suggests that data usage and contract renewal may be key factors in customer churn. Customers who do not use a lot of data or do not renew their contracts are more likely to churn. However, more analysis would be needed to confirm these findings and identify other potential factors.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Senior Data Analyst] Task output: 1. AccountWeeks: The length of the customer's account varies across the data with the range of 27 to 200 weeks. There doesn't seem to be a direct correlation between the length of the account and customer churn based on the data provided. Both customers with short and long account lengths have churned.\n",
            "\n",
            "2. DataUsage: The data usage also varies across the data, ranging from 0.0 to 4.13. Interestingly, customers with 0 data usage have both churned and not churned. However, there is a slight trend that customers with higher data usage tend to not churn, suggesting that customers who utilize more services are less likely to churn.\n",
            "\n",
            "3. ContractRenewal: Most of the customers in the data have renewed their contract (ContractRenewal = 1). However, there are also customers who have not renewed their contracts and have churned. This suggests that customers who do not renew their contracts are more likely to churn.\n",
            "\n",
            "4. RoamMins: There does not seem to be a clear trend between the number of roaming minutes and customer churn. Customers with various amounts of roaming minutes have both churned and not churned.\n",
            "\n",
            "Overall, the data suggests that data usage and contract renewal may be key factors in customer churn. Customers who do not use a lot of data or do not renew their contracts are more likely to churn. However, more analysis would be needed to confirm these findings and identify other potential factors.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Senior Data Scientist\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Using the insights provided, develop a machine learning   model to predict the Churn.\n",
            "  The model should follow machine learning best practice, especially from   preprocessing to validation.\n",
            "  Your Final answer must be the full python code, only the python code and nothing else.\n",
            "  \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI now can give a great answer\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "```python\n",
            "# Importing Required Libraries\n",
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.metrics import classification_report, confusion_matrix\n",
            "\n",
            "# Assuming data is stored in a csv file named 'data.csv'\n",
            "data = pd.read_csv('data.csv')\n",
            "\n",
            "# Preprocessing the data\n",
            "# Assigning the dependent and independent variables\n",
            "X = data[['AccountWeeks', 'DataUsage', 'ContractRenewal', 'RoamMins']]\n",
            "y = data['Churn']\n",
            "\n",
            "# Splitting the data into training and testing sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "\n",
            "# Scaling the data\n",
            "scaler = StandardScaler()\n",
            "X_train = scaler.fit_transform(X_train)\n",
            "X_test = scaler.transform(X_test)\n",
            "\n",
            "# Building the Logistic Regression Model\n",
            "model = LogisticRegression()\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# Predicting Churn\n",
            "predictions = model.predict(X_test)\n",
            "\n",
            "# Evaluating the model\n",
            "print(classification_report(y_test, predictions))\n",
            "print(confusion_matrix(y_test, predictions))\n",
            "```\n",
            "\n",
            "This Python code first imports the necessary libraries and loads the data. It then preprocesses the data by splitting it into training and testing sets and scaling it. A logistic regression model is then built and fit to the training data. The model is used to predict churn on the testing data, and the results are evaluated using a classification report and confusion matrix.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Senior Data Scientist] Task output: ```python\n",
            "# Importing Required Libraries\n",
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.metrics import classification_report, confusion_matrix\n",
            "\n",
            "# Assuming data is stored in a csv file named 'data.csv'\n",
            "data = pd.read_csv('data.csv')\n",
            "\n",
            "# Preprocessing the data\n",
            "# Assigning the dependent and independent variables\n",
            "X = data[['AccountWeeks', 'DataUsage', 'ContractRenewal', 'RoamMins']]\n",
            "y = data['Churn']\n",
            "\n",
            "# Splitting the data into training and testing sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "\n",
            "# Scaling the data\n",
            "scaler = StandardScaler()\n",
            "X_train = scaler.fit_transform(X_train)\n",
            "X_test = scaler.transform(X_test)\n",
            "\n",
            "# Building the Logistic Regression Model\n",
            "model = LogisticRegression()\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# Predicting Churn\n",
            "predictions = model.predict(X_test)\n",
            "\n",
            "# Evaluating the model\n",
            "print(classification_report(y_test, predictions))\n",
            "print(confusion_matrix(y_test, predictions))\n",
            "```\n",
            "\n",
            "This Python code first imports the necessary libraries and loads the data. It then preprocesses the data by splitting it into training and testing sets and scaling it. A logistic regression model is then built and fit to the training data. The model is used to predict churn on the testing data, and the results are evaluated using a classification report and confusion matrix.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Senior Machine Learning Engineer\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: From the code you get, develop a Python code to deploy   the machine learning model in the production application.\n",
            "  The model deployment should follow the best practice.\n",
            "  The model object should be the output.\n",
            "  Start simple, and iterate if it is required.\n",
            "  Your Final answer must be the full python code from the machine   learning development to the model deploying, only the python code and nothing else.\n",
            "  \u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThe given code does a good job at building a machine learning model for predicting churn. However, it doesn't include the part where the model is saved or deployed for future use in a production environment. To deploy this machine learning model, I will use the joblib library to save the model and the StandardScaler. This allows us to use these for future predictions without having to retrain the model or rescale the data. \n",
            "\n",
            "Here's my final code:\n",
            "\n",
            "```python\n",
            "# Importing Required Libraries\n",
            "import pandas as pd\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.preprocessing import StandardScaler\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.metrics import classification_report, confusion_matrix\n",
            "from joblib import dump, load\n",
            "\n",
            "# Assuming data is stored in a csv file named 'data.csv'\n",
            "data = pd.read_csv('data.csv')\n",
            "\n",
            "# Preprocessing the data\n",
            "# Assigning the dependent and independent variables\n",
            "X = data[['AccountWeeks', 'DataUsage', 'ContractRenewal', 'RoamMins']]\n",
            "y = data['Churn']\n",
            "\n",
            "# Splitting the data into training and testing sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "\n",
            "# Scaling the data\n",
            "scaler = StandardScaler()\n",
            "X_train = scaler.fit_transform(X_train)\n",
            "X_test = scaler.transform(X_test)\n",
            "\n",
            "# Building the Logistic Regression Model\n",
            "model = LogisticRegression()\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# Save the model for deployment\n",
            "dump(model, 'model.joblib')\n",
            "dump(scaler, 'scaler.joblib')\n",
            "\n",
            "# Load the model and scaler for deployment\n",
            "model = load('model.joblib')\n",
            "scaler = load('scaler.joblib')\n",
            "\n",
            "# Predicting Churn with the deployed model and scaler\n",
            "predictions = model.predict(scaler.transform(X_test))\n",
            "\n",
            "# Evaluating the model\n",
            "print(classification_report(y_test, predictions))\n",
            "print(confusion_matrix(y_test, predictions))\n",
            "```\n",
            "\n",
            "Thought: I now can give a great answer\n",
            "Final Answer: The final answer is the Python code provided above. It trains a machine learning model, scales the data, and then saves both the model and scaler for deployment. It then loads the saved model and scaler to make predictions, proving that the model and scaler were saved and loaded correctly.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Senior Machine Learning Engineer] Task output: The final answer is the Python code provided above. It trains a machine learning model, scales the data, and then saves both the model and scaler for deployment. It then loads the saved model and scaler to make predictions, proving that the model and scaler were saved and loaded correctly.\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod organizuje i uruchamia pracę zespołu agentów AI:\n",
        "\n",
        "`crew = Crew()` tworzy zespół z następującymi parametrami:\n",
        "- Lista agentów: analityk danych, naukowiec danych i inżynier ML\n",
        "- Lista zadań: analiza danych, tworzenie modelu ML i wdrożenie modelu\n",
        "- `verbose=2` - wysoki poziom szczegółowości raportowania działań\n",
        "\n",
        "`result = crew.kickoff()` uruchamia sekwencję zadań:\n",
        "1. Analityk przeprowadza analizę danych z pliku CSV\n",
        "2. Naukowiec danych wykorzystuje te wyniki do stworzenia modelu uczenia maszynowego\n",
        "3. Inżynier ML przygotowuje kod do wdrożenia tego modelu w środowisku produkcyjnym\n",
        "\n",
        "Zadania są wykonywane w określonej kolejności, gdzie każde następne zadanie korzysta z wyników poprzedniego. Wszystkie wyniki są zapisywane w zmiennej `result`."
      ],
      "metadata": {
        "id": "kannqGYA8FJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewQ8FJ1w9RGY",
        "outputId": "590d0d7d-f0ef-432e-b936-4a664b4fdc4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Task(description=Conduct a comprehensive analysis from the CSV dataset   by using the tools provided.\n",
              "  You only need to run the tools and without providing any 'tool_input', as   the tools already have the source data path embedded to it.\n",
              "  Identify any analysis that related to why churn is happening. , expected_output=Full analysis report)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1.output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7EEq1jt93AH",
        "outputId": "3fe4efb6-112d-41fc-c97a-32449eed2b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskOutput(description=\"Conduct a comprehensive analysis from the CSV dataset   by using the tools provided.\\n  You only need to run the tools and without providing any 'tool_input', as   the tools already have the source data path embedded to it.\\n  Identify any analysis that related to why churn is happening. \", summary='Conduct a comprehensive analysis from the CSV dataset  ...', exported_output=\"1. AccountWeeks: The length of the customer's account varies across the data with the range of 27 to 200 weeks. There doesn't seem to be a direct correlation between the length of the account and customer churn based on the data provided. Both customers with short and long account lengths have churned.\\n\\n2. DataUsage: The data usage also varies across the data, ranging from 0.0 to 4.13. Interestingly, customers with 0 data usage have both churned and not churned. However, there is a slight trend that customers with higher data usage tend to not churn, suggesting that customers who utilize more services are less likely to churn.\\n\\n3. ContractRenewal: Most of the customers in the data have renewed their contract (ContractRenewal = 1). However, there are also customers who have not renewed their contracts and have churned. This suggests that customers who do not renew their contracts are more likely to churn.\\n\\n4. RoamMins: There does not seem to be a clear trend between the number of roaming minutes and customer churn. Customers with various amounts of roaming minutes have both churned and not churned.\\n\\nOverall, the data suggests that data usage and contract renewal may be key factors in customer churn. Customers who do not use a lot of data or do not renew their contracts are more likely to churn. However, more analysis would be needed to confirm these findings and identify other potential factors.\", raw_output=\"1. AccountWeeks: The length of the customer's account varies across the data with the range of 27 to 200 weeks. There doesn't seem to be a direct correlation between the length of the account and customer churn based on the data provided. Both customers with short and long account lengths have churned.\\n\\n2. DataUsage: The data usage also varies across the data, ranging from 0.0 to 4.13. Interestingly, customers with 0 data usage have both churned and not churned. However, there is a slight trend that customers with higher data usage tend to not churn, suggesting that customers who utilize more services are less likely to churn.\\n\\n3. ContractRenewal: Most of the customers in the data have renewed their contract (ContractRenewal = 1). However, there are also customers who have not renewed their contracts and have churned. This suggests that customers who do not renew their contracts are more likely to churn.\\n\\n4. RoamMins: There does not seem to be a clear trend between the number of roaming minutes and customer churn. Customers with various amounts of roaming minutes have both churned and not churned.\\n\\nOverall, the data suggests that data usage and contract renewal may be key factors in customer churn. Customers who do not use a lot of data or do not renew their contracts are more likely to churn. However, more analysis would be needed to confirm these findings and identify other potential factors.\")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task1.output.json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "gXl6oMGI9UTG",
        "outputId": "ea3abc91-bcc0-4ac5-ea80-ffb8e937c03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"description\":\"Conduct a comprehensive analysis from the CSV dataset   by using the tools provided.\\\\n  You only need to run the tools and without providing any \\'tool_input\\', as   the tools already have the source data path embedded to it.\\\\n  Identify any analysis that related to why churn is happening. \",\"summary\":\"Conduct a comprehensive analysis from the CSV dataset  ...\",\"exported_output\":\"1. AccountWeeks: The length of the customer\\'s account varies across the data with the range of 27 to 200 weeks. There doesn\\'t seem to be a direct correlation between the length of the account and customer churn based on the data provided. Both customers with short and long account lengths have churned.\\\\n\\\\n2. DataUsage: The data usage also varies across the data, ranging from 0.0 to 4.13. Interestingly, customers with 0 data usage have both churned and not churned. However, there is a slight trend that customers with higher data usage tend to not churn, suggesting that customers who utilize more services are less likely to churn.\\\\n\\\\n3. ContractRenewal: Most of the customers in the data have renewed their contract (ContractRenewal = 1). However, there are also customers who have not renewed their contracts and have churned. This suggests that customers who do not renew their contracts are more likely to churn.\\\\n\\\\n4. RoamMins: There does not seem to be a clear trend between the number of roaming minutes and customer churn. Customers with various amounts of roaming minutes have both churned and not churned.\\\\n\\\\nOverall, the data suggests that data usage and contract renewal may be key factors in customer churn. Customers who do not use a lot of data or do not renew their contracts are more likely to churn. However, more analysis would be needed to confirm these findings and identify other potential factors.\",\"raw_output\":\"1. AccountWeeks: The length of the customer\\'s account varies across the data with the range of 27 to 200 weeks. There doesn\\'t seem to be a direct correlation between the length of the account and customer churn based on the data provided. Both customers with short and long account lengths have churned.\\\\n\\\\n2. DataUsage: The data usage also varies across the data, ranging from 0.0 to 4.13. Interestingly, customers with 0 data usage have both churned and not churned. However, there is a slight trend that customers with higher data usage tend to not churn, suggesting that customers who utilize more services are less likely to churn.\\\\n\\\\n3. ContractRenewal: Most of the customers in the data have renewed their contract (ContractRenewal = 1). However, there are also customers who have not renewed their contracts and have churned. This suggests that customers who do not renew their contracts are more likely to churn.\\\\n\\\\n4. RoamMins: There does not seem to be a clear trend between the number of roaming minutes and customer churn. Customers with various amounts of roaming minutes have both churned and not churned.\\\\n\\\\nOverall, the data suggests that data usage and contract renewal may be key factors in customer churn. Customers who do not use a lot of data or do not renew their contracts are more likely to churn. However, more analysis would be needed to confirm these findings and identify other potential factors.\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json.loads(task1.output.json()).keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFjiXPT59XCb",
        "outputId": "218427a2-d2de-4499-8be0-bb8e06a76b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['description', 'summary', 'exported_output', 'raw_output'])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json.loads(task1.output.json())['description']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "4CEdrG4w9vR6",
        "outputId": "964fb38c-c35e-4aa5-d27f-db30610a9544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Conduct a comprehensive analysis from the CSV dataset   by using the tools provided.\\n  You only need to run the tools and without providing any 'tool_input', as   the tools already have the source data path embedded to it.\\n  Identify any analysis that related to why churn is happening. \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppr(json.loads(task1.output.json())['exported_output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwxUDa4F-rjd",
        "outputId": "25654d33-1216-4945-9d0b-3830d8db1fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"1. AccountWeeks: The length of the customer's account varies across the data \"\n",
            " \"with the range of 27 to 200 weeks. There doesn't seem to be a direct \"\n",
            " 'correlation between the length of the account and customer churn based on '\n",
            " 'the data provided. Both customers with short and long account lengths have '\n",
            " 'churned.\\n'\n",
            " '\\n'\n",
            " '2. DataUsage: The data usage also varies across the data, ranging from 0.0 '\n",
            " 'to 4.13. Interestingly, customers with 0 data usage have both churned and '\n",
            " 'not churned. However, there is a slight trend that customers with higher '\n",
            " 'data usage tend to not churn, suggesting that customers who utilize more '\n",
            " 'services are less likely to churn.\\n'\n",
            " '\\n'\n",
            " '3. ContractRenewal: Most of the customers in the data have renewed their '\n",
            " 'contract (ContractRenewal = 1). However, there are also customers who have '\n",
            " 'not renewed their contracts and have churned. This suggests that customers '\n",
            " 'who do not renew their contracts are more likely to churn.\\n'\n",
            " '\\n'\n",
            " '4. RoamMins: There does not seem to be a clear trend between the number of '\n",
            " 'roaming minutes and customer churn. Customers with various amounts of '\n",
            " 'roaming minutes have both churned and not churned.\\n'\n",
            " '\\n'\n",
            " 'Overall, the data suggests that data usage and contract renewal may be key '\n",
            " 'factors in customer churn. Customers who do not use a lot of data or do not '\n",
            " 'renew their contracts are more likely to churn. However, more analysis would '\n",
            " 'be needed to confirm these findings and identify other potential factors.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppr(json.loads(task2.output.json())['exported_output'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHj-fvQP-5dq",
        "outputId": "fbe1bd6e-7e76-42fa-8c33-0e2eab1eaac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('```python\\n'\n",
            " '# Importing Required Libraries\\n'\n",
            " 'import pandas as pd\\n'\n",
            " 'from sklearn.model_selection import train_test_split\\n'\n",
            " 'from sklearn.preprocessing import StandardScaler\\n'\n",
            " 'from sklearn.linear_model import LogisticRegression\\n'\n",
            " 'from sklearn.metrics import classification_report, confusion_matrix\\n'\n",
            " '\\n'\n",
            " \"# Assuming data is stored in a csv file named 'data.csv'\\n\"\n",
            " \"data = pd.read_csv('data.csv')\\n\"\n",
            " '\\n'\n",
            " '# Preprocessing the data\\n'\n",
            " '# Assigning the dependent and independent variables\\n'\n",
            " \"X = data[['AccountWeeks', 'DataUsage', 'ContractRenewal', 'RoamMins']]\\n\"\n",
            " \"y = data['Churn']\\n\"\n",
            " '\\n'\n",
            " '# Splitting the data into training and testing sets\\n'\n",
            " 'X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, '\n",
            " 'random_state=42)\\n'\n",
            " '\\n'\n",
            " '# Scaling the data\\n'\n",
            " 'scaler = StandardScaler()\\n'\n",
            " 'X_train = scaler.fit_transform(X_train)\\n'\n",
            " 'X_test = scaler.transform(X_test)\\n'\n",
            " '\\n'\n",
            " '# Building the Logistic Regression Model\\n'\n",
            " 'model = LogisticRegression()\\n'\n",
            " 'model.fit(X_train, y_train)\\n'\n",
            " '\\n'\n",
            " '# Predicting Churn\\n'\n",
            " 'predictions = model.predict(X_test)\\n'\n",
            " '\\n'\n",
            " '# Evaluating the model\\n'\n",
            " 'print(classification_report(y_test, predictions))\\n'\n",
            " 'print(confusion_matrix(y_test, predictions))\\n'\n",
            " '```\\n'\n",
            " '\\n'\n",
            " 'This Python code first imports the necessary libraries and loads the data. '\n",
            " 'It then preprocesses the data by splitting it into training and testing sets '\n",
            " 'and scaling it. A logistic regression model is then built and fit to the '\n",
            " 'training data. The model is used to predict churn on the testing data, and '\n",
            " 'the results are evaluated using a classification report and confusion '\n",
            " 'matrix.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task3.output.json()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "A7WzytXA-7Ft",
        "outputId": "1f7064e6-f9c6-413f-f8fd-b27581ce6711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"description\":\"From the code you get, develop a Python code to deploy   the machine learning model in the production application.\\\\n  The model deployment should follow the best practice.\\\\n  The model object should be the output.\\\\n  Start simple, and iterate if it is required.\\\\n  Your Final answer must be the full python code from the machine   learning development to the model deploying, only the python code and nothing else.\\\\n  \",\"summary\":\"From the code you get, develop a Python code to...\",\"exported_output\":\"The final answer is the Python code provided above. It trains a machine learning model, scales the data, and then saves both the model and scaler for deployment. It then loads the saved model and scaler to make predictions, proving that the model and scaler were saved and loaded correctly.\",\"raw_output\":\"The final answer is the Python code provided above. It trains a machine learning model, scales the data, and then saves both the model and scaler for deployment. It then loads the saved model and scaler to make predictions, proving that the model and scaler were saved and loaded correctly.\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}