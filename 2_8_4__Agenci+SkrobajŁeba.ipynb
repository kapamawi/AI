{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapamawi/AI/blob/main/2_8_4__Agenci%2BSkrobaj%C5%81eba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "_PlzQa5TtC49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxopyPya-dg0",
        "outputId": "56612bd3-37db-4c85-830a-7799236ecd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kod instaluje dwie konkretne biblioteki Pythona:\n",
        "\n",
        "1. openai w wersji 1.55.3 - jest to oficjalna biblioteka do komunikacji z API OpenAI\n",
        "2. httpx w wersji 0.27.2 - to klient HTTP dla Pythona, który wspiera nowoczesne protokoły i standardy\n",
        "\n",
        "Flagi użyte w poleceniu instalacyjnym:\n",
        "- `-q` lub `--quiet` - wycisza większość komunikatów podczas instalacji\n",
        "- `--force-reinstall` - wymusza ponowną instalację, nawet jeśli pakiety są już zainstalowane\n",
        "- `--quiet` - dodatkowe wyciszenie komunikatów (dubel z `-q`)\n",
        "\n",
        "Użycie znaku wykrzyknika na początku (`!pip`) wskazuje, że kod jest wykonywany w środowisku Jupyter Notebook lub Google Colab, gdzie taka składnia pozwala na uruchamianie poleceń systemowych.\n",
        "\n",
        "Ta konfiguracja jest typowym pierwszym krokiem przy pracy z API OpenAI, gdzie biblioteka httpx służy jako zależność do obsługi połączeń sieciowych."
      ],
      "metadata": {
        "id": "N8idzfGf_XkU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BUk4XB1s7b8"
      },
      "outputs": [],
      "source": [
        "! pip install -q autogen-agentchat~=0.2 apify-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod instaluje dwie biblioteki Pythona:\n",
        "\n",
        "1. autogen-agentchat w wersji około 0.2 (symbol `~=` oznacza, że może być zainstalowana wersja 0.2.x, ale nie 0.3) - jest to biblioteka do tworzenia konwersacyjnych agentów AI\n",
        "\n",
        "2. apify-client - klient do platformy Apify, która służy do web scrapingu i automatyzacji zadań w internecie\n",
        "\n",
        "Flagi i notacja:\n",
        "- `!` na początku oznacza wykonanie polecenia systemowego w Jupyter Notebook lub Google Colab\n",
        "- `-q` wycisza większość komunikatów podczas instalacji\n",
        "- `~=` to operator kompatybilności wersji, który pozwala na instalację poprawek w ramach tej samej wersji minor\n"
      ],
      "metadata": {
        "id": "uMSJN6hXFVOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "from apify_client import ApifyClient\n",
        "from typing_extensions import Annotated\n",
        "\n",
        "from autogen import ConversableAgent, register_function\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVKTsl2eto_N",
        "outputId": "1e34210c-c8c3-48f9-9275-2e4423fdcd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod importuje niezbędne biblioteki i komponenty:\n",
        "\n",
        "1. `from google.colab import userdata` - importuje moduł do obsługi danych użytkownika w środowisku Google Colab\n",
        "\n",
        "2. `import os` - importuje moduł do operacji systemowych, pozwala na pracę ze zmiennymi środowiskowymi i ścieżkami\n",
        "\n",
        "3. `from apify_client import ApifyClient` - importuje klienta do platformy Apify, służącego do web scrapingu\n",
        "\n",
        "4. `from typing_extensions import Annotated` - importuje typ Annotated z rozszerzeń typing, używany do dodawania metadanych do typów\n",
        "\n",
        "5. `from autogen import ConversableAgent, register_function` - importuje dwa komponenty z biblioteki autogen:\n",
        "   - ConversableAgent - bazową klasę do tworzenia agentów zdolnych do prowadzenia konwersacji\n",
        "   - register_function - dekorator do rejestrowania funkcji, które mogą być używane przez agentów\n",
        "\n",
        "Te importy tworzą podstawę do budowy systemu, który może łączyć funkcje agentów konwersacyjnych ze zbieraniem danych z internetu, z wykorzystaniem specyficznych funkcji Google Colab."
      ],
      "metadata": {
        "id": "f_lLiSVUFrp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "  model = 'gpt-4o-mini'"
      ],
      "metadata": {
        "id": "zeKS26L8uA1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configs\n",
        "\n",
        "config_list = [\n",
        "    {\"model\": CFG.model, \"api_key\": userdata.get('openaivision')},\n",
        "]\n",
        "\n",
        "apify_api_key = userdata.get('apify')"
      ],
      "metadata": {
        "id": "LGpxI1_EtwlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten fragment kodu konfiguruje kluczowe ustawienia:\n",
        "\n",
        "1. `config_list` to lista zawierająca słownik z dwiema wartościami:\n",
        "   - `model` - pobiera model z obiektu CFG (zdefiniowanego wcześniej)\n",
        "   - `api_key` - pobiera klucz API do OpenAI Vision z danych użytkownika Colab\n",
        "\n",
        "2. `apify_api_key` - zapisuje w zmiennej klucz API do platformy Apify, również pobrany z danych użytkownika Colab\n",
        "\n",
        "W obu przypadkach użyto metody `userdata.get()`, która bezpiecznie pobiera poufne dane uwierzytelniające przechowywane w środowisku Google Colab. Ten sposób przechowywania kluczy API jest bezpieczniejszy niż umieszczanie ich bezpośrednio w kodzie.\n",
        "\n",
        "Ta konfiguracja przygotowuje środowisko do pracy zarówno z modelami wizyjnymi OpenAI, jak i usługami Apify."
      ],
      "metadata": {
        "id": "F9NypXNiGCx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "VbwMq6G44J3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_page(url: Annotated[str, \"The URL of the web page to scrape\"]) -> Annotated[str, \"Scraped content\"]:\n",
        "    # Initialize the ApifyClient with your API token\n",
        "    client = ApifyClient(token=apify_api_key)\n",
        "\n",
        "    # Prepare the Actor input\n",
        "    run_input = {\n",
        "        \"startUrls\": [{\"url\": url}],\n",
        "        \"useSitemaps\": False,\n",
        "        \"crawlerType\": \"playwright:firefox\",\n",
        "        \"includeUrlGlobs\": [],\n",
        "        \"excludeUrlGlobs\": [],\n",
        "        \"ignoreCanonicalUrl\": False,\n",
        "        \"maxCrawlDepth\": 0,\n",
        "        \"maxCrawlPages\": 1,\n",
        "        \"initialConcurrency\": 0,\n",
        "        \"maxConcurrency\": 200,\n",
        "        \"initialCookies\": [],\n",
        "        \"proxyConfiguration\": {\"useApifyProxy\": True},\n",
        "        \"maxSessionRotations\": 10,\n",
        "        \"maxRequestRetries\": 5,\n",
        "        \"requestTimeoutSecs\": 60,\n",
        "        \"dynamicContentWaitSecs\": 10,\n",
        "        \"maxScrollHeightPixels\": 5000,\n",
        "        \"removeElementsCssSelector\": \"\"\"nav, footer, script, style, noscript, svg,\n",
        "    [role=\\\"alert\\\"],\n",
        "    [role=\\\"banner\\\"],\n",
        "    [role=\\\"dialog\\\"],\n",
        "    [role=\\\"alertdialog\\\"],\n",
        "    [role=\\\"region\\\"][aria-label*=\\\"skip\\\" i],\n",
        "    [aria-modal=\\\"true\\\"]\"\"\",\n",
        "        \"removeCookieWarnings\": True,\n",
        "        \"clickElementsCssSelector\": '[aria-expanded=\"false\"]',\n",
        "        \"htmlTransformer\": \"readableText\",\n",
        "        \"readableTextCharThreshold\": 100,\n",
        "        \"aggressivePrune\": False,\n",
        "        \"debugMode\": True,\n",
        "        \"debugLog\": True,\n",
        "        \"saveHtml\": True,\n",
        "        \"saveMarkdown\": True,\n",
        "        \"saveFiles\": False,\n",
        "        \"saveScreenshots\": False,\n",
        "        \"maxResults\": 9999999,\n",
        "        \"clientSideMinChangePercentage\": 15,\n",
        "        \"renderingTypeDetectionPercentage\": 10,\n",
        "    }\n",
        "\n",
        "    # Run the Actor and wait for it to finish\n",
        "    run = client.actor(\"aYG0l9s7dbB7j3gbS\").call(run_input=run_input)\n",
        "\n",
        "    # Fetch and print Actor results from the run's dataset (if there are any)\n",
        "    text_data = \"\"\n",
        "    for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
        "        text_data += item.get(\"text\", \"\") + \"\\n\"\n",
        "\n",
        "    average_token = 0.75\n",
        "    max_tokens = 20000  # slightly less than max to be safe 32k\n",
        "    text_data = text_data[: int(average_token * max_tokens)]\n",
        "    return text_data"
      ],
      "metadata": {
        "id": "47VAZWG54KtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta funkcja `scrape_page` służy do zaawansowanego scrapowania stron internetowych:\n",
        "\n",
        "1. Przyjmuje parametr `url` (z adnotacją typu wskazującą, że to adres strony do scrapowania) i zwraca wydobytą treść tekstową.\n",
        "\n",
        "2. Inicjalizuje klienta Apify używając wcześniej skonfigurowanego klucza API.\n",
        "\n",
        "3. Konfiguruje szczegółowe parametry scrapowania w `run_input`:\n",
        "   - Ogranicza crawling do jednej strony (`maxCrawlPages`: 1)\n",
        "   - Używa przeglądarki Firefox przez Playwright\n",
        "   - Ustawia proxy Apify\n",
        "   - Definiuje maksymalny czas oczekiwania i próby ponowienia\n",
        "   - Usuwa zbędne elementy strony (nawigację, stopkę, skrypty)\n",
        "   - Usuwa ostrzeżenia o ciasteczkach\n",
        "   - Rozwija zwinięte elementy\n",
        "   - Zapisuje wyniki w formacie HTML i Markdown\n",
        "\n",
        "4. Uruchamia aktora Apify o ID \"aYG0l9s7dbB7j3gbS\" z tymi ustawieniami.\n",
        "\n",
        "5. Zbiera wyniki z datasetu:\n",
        "   - Łączy wszystkie znalezione teksty\n",
        "   - Ogranicza długość wyniku do około 20000 tokenów (używając współczynnika 0.75 tokena na znak)\n",
        "\n",
        "Funkcja jest zoptymalizowana pod kątem czytelności wyników i obsługi dynamicznych stron internetowych."
      ],
      "metadata": {
        "id": "BIMGmsQEIKR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "AvhyB7Wk4O2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "scraper_agent = ConversableAgent(\n",
        "    \"WebScraper\",\n",
        "    llm_config={\"config_list\": config_list},\n",
        "    system_message=\"You are a web scrapper and you can scrape any web page using the tools provided. \"\n",
        "    \"Returns 'TERMINATE' when the scraping is done.\",\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "o_w8C4064Pee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod tworzy agenta do scrapowania stron (`scraper_agent`) używając klasy `ConversableAgent`:\n",
        "\n",
        "1. Nadaje mu nazwę \"WebScraper\"\n",
        "\n",
        "2. Konfiguruje model językowy poprzez `llm_config`, który używa wcześniej zdefiniowanej listy `config_list` z ustawieniami modelu i kluczem API\n",
        "\n",
        "3. Definiuje wiadomość systemową określającą rolę i zachowanie agenta:\n",
        "   - Agent identyfikuje się jako web scraper\n",
        "   - Ma możliwość scrapowania dowolnej strony przy użyciu dostarczonych narzędzi\n",
        "   - Zwraca 'TERMINATE' po zakończeniu scrapowania\n",
        "\n",
        "Ten agent będzie mógł prowadzić konwersację i wykonywać zadania scrapowania w odpowiedzi na polecenia użytkownika."
      ],
      "metadata": {
        "id": "Mw6E196-Mp6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_proxy_agent = ConversableAgent(\n",
        "    \"UserProxy\",\n",
        "    llm_config=False,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    code_execution_config=False,\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\") is not None and \"terminate\" in x[\"content\"].lower(),\n",
        "    default_auto_reply=\"Please continue if not finished, otherwise return 'TERMINATE'.\",\n",
        ")"
      ],
      "metadata": {
        "id": "QpcRxq595N79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod tworzy agenta reprezentującego użytkownika (`user_proxy_agent`) z następującymi ustawieniami:\n",
        "\n",
        "1. Nazwa agenta to \"UserProxy\"\n",
        "\n",
        "2. `llm_config=False` - wyłącza model językowy dla tego agenta, co oznacza że nie będzie generował własnych odpowiedzi\n",
        "\n",
        "3. `human_input_mode=\"NEVER\"` - agent nigdy nie będzie prosił o input od człowieka\n",
        "\n",
        "4. `code_execution_config=False` - wyłącza możliwość wykonywania kodu przez tego agenta\n",
        "\n",
        "5. Definiuje funkcję sprawdzającą warunek zakończenia:\n",
        "   - `is_termination_msg=lambda x: x.get(\"content\", \"\") is not None and \"terminate\" in x[\"content\"].lower()`\n",
        "   - Sprawdza czy wiadomość zawiera słowo \"terminate\" (niezależnie od wielkości liter)\n",
        "\n",
        "6. `default_auto_reply` ustawia domyślną odpowiedź:\n",
        "   - \"Please continue if not finished, otherwise return 'TERMINATE'.\"\n",
        "   - Ta wiadomość jest wysyłana automatycznie gdy agent nie ma innych instrukcji\n",
        "\n",
        "Ten agent służy jako pośrednik między systemem a prawdziwym użytkownikiem, automatyzując interakcje bez potrzeby ręcznego wprowadzania danych."
      ],
      "metadata": {
        "id": "pI0t-mYNM3Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "register_function(\n",
        "    scrape_page,\n",
        "    caller=scraper_agent,\n",
        "    executor=user_proxy_agent,\n",
        "    name=\"scrape_page\",\n",
        "    description=\"Scrape a web page and return the content.\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "hvg4K3ZC9y_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod rejestruje funkcję `scrape_page` w systemie agentów:\n",
        "\n",
        "1. `scrape_page` - rejestrowana funkcja do scrapowania stron\n",
        "\n",
        "2. `caller=scraper_agent` - określa, że scraper_agent może wywoływać tę funkcję\n",
        "\n",
        "3. `executor=user_proxy_agent` - wskazuje, że user_proxy_agent będzie wykonywał tę funkcję\n",
        "\n",
        "4. `name=\"scrape_page\"` - definiuje nazwę, pod którą funkcja będzie dostępna\n",
        "\n",
        "5. `description=\"Scrape a web page and return the content.\"` - dodaje opis funkcjonalności\n",
        "\n",
        "Ta rejestracja umożliwia współpracę między agentami - scraper_agent może zlecać zadania scrapowania, które będą wykonywane przez user_proxy_agent."
      ],
      "metadata": {
        "id": "t0kZcApCOQ9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "f5t2de0H989u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_result = user_proxy_agent.initiate_chat(\n",
        "    scraper_agent,\n",
        "    message=\"Can you scrape agentops.ai for me?\",\n",
        "    summary_method=\"reflection_with_llm\",\n",
        "    summary_args={\n",
        "        \"summary_prompt\": \"\"\"Summarize the scraped content and format summary EXACTLY as follows:\n",
        "---\n",
        "*Company name*:\n",
        "`Acme Corp`\n",
        "---\n",
        "*Website*:\n",
        "`acmecorp.com`\n",
        "---\n",
        "*Description*:\n",
        "`Company that does things.`\n",
        "---\n",
        "*Tags*:\n",
        "`Manufacturing. Retail. E-commerce.`\n",
        "---\n",
        "*Takeaways*:\n",
        "`Provides shareholders with value by selling products.`\n",
        "---\n",
        "*Questions*:\n",
        "`What products do they sell? How do they make money? What is their market share?`\n",
        "---\n",
        "\"\"\"\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a9ewFE792AB",
        "outputId": "3e7f67f5-769c-4fdb-c0bc-a3995b7a622c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UserProxy (to WebScraper):\n",
            "\n",
            "Can you scrape agentops.ai for me?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "WebScraper (to UserProxy):\n",
            "\n",
            "***** Suggested tool call (call_AmEdRdxwobx4rKwofvFKsTLE): scrape_page *****\n",
            "Arguments: \n",
            "{\"url\":\"https://agentops.ai\"}\n",
            "****************************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION scrape_page...\n",
            "UserProxy (to WebScraper):\n",
            "\n",
            "UserProxy (to WebScraper):\n",
            "\n",
            "***** Response from calling tool (call_AmEdRdxwobx4rKwofvFKsTLE) *****\n",
            "AgentOps\n",
            "Every Agent\n",
            "Needs AgentOps.\n",
            "Industry leading developer platform to test and debug AI agents. \n",
            "We built the tools so you don't have to.\n",
            "Powering thousands of engineers building reliable agents\n",
            "Action Research agent\n",
            "Update DB\n",
            "Updated successfully\n",
            "Timings\n",
            "Start - End\n",
            "19.91s - 23.38s\n",
            "Visualize\n",
            "Visually track events such as LLM calls, tools, and multi-agent interactions.\n",
            "Time Travel Debugging\n",
            "Rewind and replay agent runs with point in time precision.\n",
            "Debug and Audit\n",
            "Keep a full data trail of logs, errors, and prompt injection attacks from prototype to production.\n",
            "One SDK. Many integrations.\n",
            "Native integrations with the top agent frameworks\n",
            "Track spending\n",
            "Across multiple agents.\n",
            "Research analyst\n",
            "Total spend $3.00\n",
            "Base Agent\n",
            "Fine-tuned Agent\n",
            "Token Counts\n",
            "Track, save, and monitor every token your agent sees.\n",
            "Cost Tracking\n",
            "Manage and vizualize agent spend with up-to-date price monitoring.\n",
            "Fine-tuning\n",
            "Fine-tune specialized LLMs up to 25x cheaper on saved completions.\n",
            "Pricing\n",
            "Free to get started. Flexibility at scale.\n",
            "Basic \n",
            "$0 per month\n",
            "Free up to 1,000 events\n",
            "Features\n",
            "Agent Agnostic SDK\n",
            "LLM Cost Tracking (400+ LLMs)\n",
            "Replay Analytics\n",
            "Pro starts at\n",
            "$40 per month\n",
            "Up to 10,000 events\n",
            "Everything in Basic plus:\n",
            "Custom Tests\n",
            "Time Travel Debugging\n",
            "Email Support\n",
            "Role-based permissioning\n",
            "LLM Threat Detection\n",
            "Enterprise starts at\n",
            "Custom \n",
            "Going beyond? Let's chat\n",
            "Everything in Pro plus:\n",
            "SLA\n",
            "Slack Connect\n",
            "Custom SSO\n",
            "On-premise deployment\n",
            "Custom data retention policy\n",
            "Self-hosting (AWS, GCP, Azure)\n",
            "SOC-2, HIPAA, NIST AI RMF\n",
            "Need help building agents?\n",
            "We've tested 240+ agents. We know which ones actually work.\n",
            "The future is High Agency. \n",
            "Are you ready to build it?\n",
            "\n",
            "**********************************************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "WebScraper (to UserProxy):\n",
            "\n",
            "I have scraped the content from the webpage agentops.ai. Here are the key highlights:\n",
            "\n",
            "- **Tagline:** \"Every Agent Needs AgentOps.\"\n",
            "- **Description:** Industry-leading developer platform to test and debug AI agents. It is crafted to power thousands of engineers building reliable agents.\n",
            "- **Features:**\n",
            "  - **Visualize:** Track events such as LLM calls, tools, and multi-agent interactions.\n",
            "  - **Time Travel Debugging:** Rewind and replay agent runs with point-in-time precision.\n",
            "  - **Debug and Audit:** Maintain a full data trail of logs, errors, and prompt injection attacks from prototype to production.\n",
            "  - **SDK Integrations:** Native integrations with top agent frameworks.\n",
            "  - **Cost Management:** Monitor spending across multiple agents, with capabilities for token counts and fine-tuning.\n",
            "\n",
            "- **Pricing:**\n",
            "  - **Basic:** Free up to 1,000 events.\n",
            "  - **Pro:** Starting at $40 per month for up to 10,000 events.\n",
            "  - **Enterprise:** Custom pricing for larger needs.\n",
            "\n",
            "- **Support:** Offers help in building agents with experience from testing over 240 agents.\n",
            "\n",
            "If you need more specific information or further assistance, let me know! \n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mtDZWNlzOTBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_result.summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND3XSD4Q97sD",
        "outputId": "c0beb098-151d-4551-fb1b-c5eca24df194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "*Company name*:\n",
            "`AgentOps`\n",
            "---\n",
            "*Website*:\n",
            "`agentops.ai`\n",
            "---\n",
            "*Description*:\n",
            "`Industry-leading developer platform to test and debug AI agents.`\n",
            "---\n",
            "*Tags*:\n",
            "`AI. Development. Debugging. Cost Management.`\n",
            "---\n",
            "*Takeaways*:\n",
            "`Offers tools for visualizing agent interactions, time travel debugging, and comprehensive cost tracking.`\n",
            "---\n",
            "*Questions*:\n",
            "`What specific AI agents can be built with AgentOps? How does the pricing model scale with usage? What integrated frameworks are supported?`\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod inicjuje rozmowę między agentami w celu zebrania i analizy danych o stronie agentops.ai:\n",
        "\n",
        "1. `user_proxy_agent.initiate_chat()` rozpoczyna konwersację z następującymi parametrami:\n",
        "\n",
        "2. Partnerem rozmowy jest `scraper_agent`\n",
        "\n",
        "3. Wiadomość początkowa to prośba o scrapowanie agentops.ai\n",
        "\n",
        "4. Metoda podsumowania jest ustawiona na \"reflection_with_llm\" - używa modelu językowego do analizy\n",
        "\n",
        "5. `summary_args` definiuje format podsumowania z dokładną strukturą:\n",
        "   - Nazwa firmy\n",
        "   - Strona internetowa\n",
        "   - Opis\n",
        "   - Tagi\n",
        "   - Główne wnioski\n",
        "   - Pytania do dalszej analizy\n",
        "\n",
        "Każda sekcja w podsumowaniu jest oznaczona markdown'em z gwiazdkami dla nagłówków i znakami backtick dla treści.\n",
        "\n",
        "Ten kod nie tylko zbierze dane ze strony, ale również automatycznie je przeanalizuje i sformatuje według podanego szablonu."
      ],
      "metadata": {
        "id": "5KdYfn0lOro-"
      }
    }
  ]
}