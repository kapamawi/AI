{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapamawi/AI/blob/main/2_9_5__AgencySwarm_agencja_uslugowa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adaptacja: https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/ai_agent_tutorials/ai_services_agency"
      ],
      "metadata": {
        "id": "XCQJG9USNuii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "6y1WgCKBDN4G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk_rB1uFC_si",
        "outputId": "f3d9a929-510d-44b8-eee5-6c8501f1086a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.8/115.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq python-dotenv==1.0.1 agency-swarm==0.4.1 streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod instaluje trzy biblioteki Pythona za pomocą managera pakietów pip:\n",
        "\n",
        "1. python-dotenv w wersji 1.0.1 - biblioteka do wczytywania zmiennych środowiskowych z pliku .env\n",
        "\n",
        "2. agency-swarm w wersji 0.4.1 - framework do tworzenia systemów wieloagentowych\n",
        "\n",
        "3. streamlit - biblioteka do tworzenia interaktywnych aplikacji webowych\n",
        "\n",
        "Flaga -qq sprawia, że pip wyświetla tylko najważniejsze komunikaty podczas instalacji, pomijając szczegółowe logi i ostrzeżenia."
      ],
      "metadata": {
        "id": "CNfaN2OMMgB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J01s_DjxMask",
        "outputId": "d9c211fe-eb37-4388-dada-3eef44d8feef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "added 22 packages in 6s\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta komenda instaluje narzędzie `localtunnel` za pomocą menedżera pakietów npm (Node Package Manager).\n",
        "\n",
        "`localtunnel` to narzędzie, które tworzy publiczny URL dla lokalnie uruchomionego serwera. Pozwala to na udostępnienie aplikacji działającej na lokalnym komputerze przez internet - inni użytkownicy mogą uzyskać do niej dostęp przez wygenerowany adres URL.\n",
        "\n",
        "Jest to szczególnie przydatne podczas:\n",
        "- testowania webhooków\n",
        "- demonstrowania aplikacji klientom/współpracownikom\n",
        "- debugowania aplikacji w różnych środowiskach\n",
        "- udostępniania lokalnej aplikacji bez konieczności wdrażania jej na serwer produkcyjny"
      ],
      "metadata": {
        "id": "gHXP6HL8MggK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# App"
      ],
      "metadata": {
        "id": "G-mXnXewMdYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import Agent, Agency, set_openai_key, BaseTool"
      ],
      "metadata": {
        "id": "7YIZe6BuW5Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(Agency)"
      ],
      "metadata": {
        "id": "eRzCU2sCW5-Z",
        "outputId": "806ade27-03d5-4694-ae2a-90c179553ef2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class Agency in module agency_swarm.agency.agency:\n",
            "\n",
            "class Agency(builtins.object)\n",
            " |  Agency(agency_chart: List, shared_instructions: str = '', shared_files: Union[str, List[str]] = None, async_mode: Literal['threading', 'tools_threading'] = None, send_message_tool_class: Type[agency_swarm.tools.send_message.SendMessageBase.SendMessageBase] = <class 'agency_swarm.tools.send_message.SendMessage.SendMessage'>, settings_path: str = './settings.json', settings_callbacks: agency_swarm.agency.agency.SettingsCallbacks = None, threads_callbacks: agency_swarm.agency.agency.ThreadsCallbacks = None, temperature: float = 0.3, top_p: float = 1.0, max_prompt_tokens: int = None, max_completion_tokens: int = None, truncation_strategy: dict = None)\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, agency_chart: List, shared_instructions: str = '', shared_files: Union[str, List[str]] = None, async_mode: Literal['threading', 'tools_threading'] = None, send_message_tool_class: Type[agency_swarm.tools.send_message.SendMessageBase.SendMessageBase] = <class 'agency_swarm.tools.send_message.SendMessage.SendMessage'>, settings_path: str = './settings.json', settings_callbacks: agency_swarm.agency.agency.SettingsCallbacks = None, threads_callbacks: agency_swarm.agency.agency.ThreadsCallbacks = None, temperature: float = 0.3, top_p: float = 1.0, max_prompt_tokens: int = None, max_completion_tokens: int = None, truncation_strategy: dict = None)\n",
            " |      Initializes the Agency object, setting up agents, threads, and core functionalities.\n",
            " |      \n",
            " |      Parameters:\n",
            " |          agency_chart: The structure defining the hierarchy and interaction of agents within the agency.\n",
            " |          shared_instructions (str, optional): A path to a file containing shared instructions for all agents. Defaults to an empty string.\n",
            " |          shared_files (Union[str, List[str]], optional): A path to a folder or a list of folders containing shared files for all agents. Defaults to None.\n",
            " |          async_mode (str, optional): Specifies the mode for asynchronous processing. In \"threading\" mode, all sub-agents run in separate threads. In \"tools_threading\" mode, all tools run in separate threads, but agents do not. Defaults to None.\n",
            " |          send_message_tool_class (Type[SendMessageBase], optional): The class to use for the send_message tool. For async communication, use `SendMessageAsyncThreading`. Defaults to SendMessage.\n",
            " |          settings_path (str, optional): The path to the settings file for the agency. Must be json. If file does not exist, it will be created. Defaults to None.\n",
            " |          settings_callbacks (SettingsCallbacks, optional): A dictionary containing functions to load and save settings for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.\n",
            " |          threads_callbacks (ThreadsCallbacks, optional): A dictionary containing functions to load and save threads for the agency. The keys must be \"load\" and \"save\". Both values must be defined. Defaults to None.\n",
            " |          temperature (float, optional): The temperature value to use for the agents. Agent-specific values will override this. Defaults to 0.3.\n",
            " |          top_p (float, optional): The top_p value to use for the agents. Agent-specific values will override this. Defaults to None.\n",
            " |          max_prompt_tokens (int, optional): The maximum number of tokens allowed in the prompt for each agent. Agent-specific values will override this. Defaults to None.\n",
            " |          max_completion_tokens (int, optional): The maximum number of tokens allowed in the completion for each agent. Agent-specific values will override this. Defaults to None.\n",
            " |          truncation_strategy (dict, optional): The truncation strategy to use for the completion for each agent. Agent-specific values will override this. Defaults to None.\n",
            " |      \n",
            " |      This constructor initializes various components of the Agency, including CEO, agents, threads, and user interactions. It parses the agency chart to set up the organizational structure and initializes the messaging tools, agents, and threads necessary for the operation of the agency. Additionally, it prepares a main thread for user interactions.\n",
            " |  \n",
            " |  delete(self)\n",
            " |      This method deletes the agency and all its agents, cleaning up any files and vector stores associated with each agent.\n",
            " |  \n",
            " |  demo_gradio(self, height=450, dark_mode=True, **kwargs)\n",
            " |      Launches a Gradio-based demo interface for the agency chatbot.\n",
            " |      \n",
            " |      Parameters:\n",
            " |          height (int, optional): The height of the chatbot widget in the Gradio interface. Default is 600.\n",
            " |          dark_mode (bool, optional): Flag to determine if the interface should be displayed in dark mode. Default is True.\n",
            " |          **kwargs: Additional keyword arguments to be passed to the Gradio interface.\n",
            " |      This method sets up and runs a Gradio interface, allowing users to interact with the agency's chatbot. It includes a text input for the user's messages and a chatbot interface for displaying the conversation. The method handles user input and chatbot responses, updating the interface dynamically.\n",
            " |  \n",
            " |  get_completion(self, message: str, message_files: List[str] = None, yield_messages: bool = False, recipient_agent: agency_swarm.agents.agent.Agent = None, additional_instructions: str = None, attachments: List[dict] = None, tool_choice: dict = None, verbose: bool = False, response_format: dict = None)\n",
            " |      Retrieves the completion for a given message from the main thread.\n",
            " |      \n",
            " |      Parameters:\n",
            " |          message (str): The message for which completion is to be retrieved.\n",
            " |          message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n",
            " |          yield_messages (bool, optional): Flag to determine if intermediate messages should be yielded. Defaults to True.\n",
            " |          recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n",
            " |          additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n",
            " |          attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n",
            " |          tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n",
            " |          parallel_tool_calls (bool, optional): Whether to enable parallel function calling during tool use. Defaults to True.\n",
            " |          verbose (bool, optional): Whether to print the intermediary messages in console. Defaults to False.\n",
            " |          response_format (dict, optional): The response format to use for the completion.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Generator or final response: Depending on the 'yield_messages' flag, this method returns either a generator yielding intermediate messages or the final response from the main thread.\n",
            " |  \n",
            " |  get_completion_parse(self, message: str, response_format: Type[~T], message_files: List[str] = None, recipient_agent: agency_swarm.agents.agent.Agent = None, additional_instructions: str = None, attachments: List[dict] = None, tool_choice: dict = None, verbose: bool = False) -> ~T\n",
            " |      Retrieves the completion for a given message from the main thread and parses the response using the provided pydantic model.\n",
            " |      \n",
            " |      Parameters:\n",
            " |          message (str): The message for which completion is to be retrieved.\n",
            " |          response_format (type(BaseModel)): The response format to use for the completion. \n",
            " |          message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n",
            " |          recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n",
            " |          additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n",
            " |          attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n",
            " |          tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n",
            " |          verbose (bool, optional): Whether to print the intermediary messages in console. Defaults to False.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Final response: The final response from the main thread, parsed using the provided pydantic model.\n",
            " |  \n",
            " |  get_completion_stream(self, message: str, event_handler: abc.ABCMeta, message_files: List[str] = None, recipient_agent: agency_swarm.agents.agent.Agent = None, additional_instructions: str = None, attachments: List[dict] = None, tool_choice: dict = None, response_format: dict = None)\n",
            " |      Generates a stream of completions for a given message from the main thread.\n",
            " |      \n",
            " |      Parameters:\n",
            " |          message (str): The message for which completion is to be retrieved.\n",
            " |          event_handler (type(AgencyEventHandler)): The event handler class to handle the completion stream. https://github.com/openai/openai-python/blob/main/helpers.md\n",
            " |          message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.\n",
            " |          recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.\n",
            " |          additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.\n",
            " |          attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.\n",
            " |          tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.\n",
            " |          parallel_tool_calls (bool, optional): Whether to enable parallel function calling during tool use. Defaults to True.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Final response: Final response from the main thread.\n",
            " |  \n",
            " |  get_customgpt_schema(self, url: str)\n",
            " |      Returns the OpenAPI schema for the agency from the CEO agent, that you can use to integrate with custom gpts.\n",
            " |      \n",
            " |      Parameters:\n",
            " |          url (str): Your server url where the api will be hosted.\n",
            " |  \n",
            " |  plot_agency_chart(self)\n",
            " |  \n",
            " |  run_demo(self)\n",
            " |      Executes agency in the terminal with autocomplete for recipient agent names.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile muh_app.py\n",
        "from typing import List, Literal, Dict, Optional\n",
        "from agency_swarm import Agent, Agency, set_openai_key, BaseTool\n",
        "from pydantic import Field, BaseModel\n",
        "import streamlit as st\n",
        "\n",
        "# narzędzia\n",
        "class AnalyzeProjectRequirements(BaseTool):\n",
        "    project_name: str = Field(..., description=\"Nazwa projektu\")\n",
        "    project_description: str = Field(..., description=\"Opis projektu i cele\")\n",
        "    project_type: Literal[\"Aplikacja webowa\", \"Aplikacja mobilna\", \"Rozwój API\",\n",
        "                         \"Analityka danych\", \"Rozwiązanie AI/ML\", \"Inne\"] = Field(..., description=\"Typ projektu\")\n",
        "    budget_range: Literal[\"10k-25k zł\", \"25k-50k zł\", \"50k-100k zł\", \"100k+ zł\"] = Field(...,\n",
        "                         description=\"Zakres budżetu projektu\")\n",
        "\n",
        "    class ToolConfig:\n",
        "        name = \"analyze_project\"\n",
        "        description = \"Analizuje wymagania i wykonalność projektu\"\n",
        "        one_call_at_a_time = True\n",
        "\n",
        "    def run(self) -> str:\n",
        "        \"\"\"Analizuje projekt i zapisuje wyniki w współdzielonym stanie\"\"\"\n",
        "        if self._shared_state.get(\"project_analysis\", None) is not None:\n",
        "            raise ValueError(\"Analiza projektu już istnieje. Proszę przejść do specyfikacji technicznej.\")\n",
        "\n",
        "        analysis = {\n",
        "            \"name\": self.project_name,\n",
        "            \"type\": self.project_type,\n",
        "            \"complexity\": \"wysoka\",\n",
        "            \"timeline\": \"6 miesięcy\",\n",
        "            \"budget_feasibility\": \"w zakresie\",\n",
        "            \"requirements\": [\"Skalowalna architektura\", \"Bezpieczeństwo\", \"Integracja API\"]\n",
        "        }\n",
        "\n",
        "        self._shared_state.set(\"project_analysis\", analysis)\n",
        "        return \"Analiza projektu zakończona. Proszę przejść do specyfikacji technicznej.\"\n",
        "\n",
        "class CreateTechnicalSpecification(BaseTool):\n",
        "    architecture_type: Literal[\"monolityczna\", \"mikroserwisy\", \"serverless\", \"hybrydowa\"] = Field( ..., description=\"Proponowany typ architektury\")\n",
        "    core_technologies: str = Field(...,  description=\"Lista głównych technologii i frameworków oddzielonych przecinkami\" )\n",
        "    scalability_requirements: Literal[\"wysoka\", \"średnia\", \"niska\"] = Field( ...,  description=\"Wymagania skalowalności\" )\n",
        "\n",
        "    class ToolConfig:\n",
        "      name = \"create_technical_spec\"\n",
        "      description = \"Tworzy specyfikację techniczną na podstawie analizy projektu\"\n",
        "      one_call_at_a_time = True\n",
        "\n",
        "    def run(self) -> str:\n",
        "        \"\"\"Tworzy specyfikację techniczną na podstawie analizy\"\"\"\n",
        "        project_analysis = self._shared_state.get(\"project_analysis\", None)\n",
        "        if project_analysis is None:\n",
        "            raise ValueError(\"Proszę najpierw przeanalizować wymagania projektu używając narzędzia AnalyzeProjectRequirements.\")\n",
        "\n",
        "        spec = {\n",
        "            \"project_name\": project_analysis[\"name\"],\n",
        "            \"architecture\": self.architecture_type,\n",
        "            \"technologies\": self.core_technologies.split(\",\"),\n",
        "            \"scalability\": self.scalability_requirements\n",
        "        }\n",
        "\n",
        "        self._shared_state.set(\"technical_specification\", spec)\n",
        "        return f\"Utworzono specyfikację techniczną dla {project_analysis['name']}.\"\n",
        "\n",
        "def init_session_state() -> None:\n",
        "    \"\"\"Initialize session state variables\"\"\"\n",
        "    if 'messages' not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "    if 'api_key' not in st.session_state:\n",
        "        st.session_state.api_key = None\n",
        "\n",
        "def main() -> None:\n",
        "    st.set_page_config(page_title=\"Agencja Usług AI\", layout=\"wide\")\n",
        "    init_session_state()\n",
        "\n",
        "    st.title(\"🚀 Agencja Usług AI\")\n",
        "\n",
        "    # Konfiguracja API\n",
        "    with st.sidebar:\n",
        "        st.header(\"🔑 Konfiguracja API\")\n",
        "        openai_api_key = st.text_input(\n",
        "            \"Klucz API OpenAI\",\n",
        "            type=\"password\",\n",
        "            help=\"Wprowadź swój klucz API OpenAI, aby kontynuować\"\n",
        "        )\n",
        "\n",
        "        if openai_api_key:\n",
        "            st.session_state.api_key = openai_api_key\n",
        "            st.success(\"Klucz API zaakceptowany!\")\n",
        "        else:\n",
        "            st.warning(\"⚠️ Proszę wprowadzić klucz API OpenAI, aby kontynuować\")\n",
        "            st.markdown(\"[Uzyskaj swój klucz API tutaj](https://platform.openai.com/api-keys)\")\n",
        "            return\n",
        "\n",
        "    # Initialize agents with the provided API key\n",
        "    set_openai_key(st.session_state.api_key)\n",
        "    api_headers = {\"Authorization\": f\"Bearer {st.session_state.api_key}\"}\n",
        "\n",
        "    # Formularz projektu\n",
        "    with st.form(\"project_form\"):\n",
        "        st.subheader(\"Szczegóły Projektu\")\n",
        "\n",
        "        project_name = st.text_input(\"Nazwa Projektu\")\n",
        "        project_description = st.text_area(\n",
        "            \"Opis Projektu\",\n",
        "            help=\"Opisz projekt, jego cele i szczególne wymagania\"\n",
        "        )\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            project_type = st.selectbox(\n",
        "                \"Typ Projektu\",\n",
        "                [\"Aplikacja webowa\", \"Aplikacja mobilna\", \"Rozwój API\",\n",
        "                 \"Analityka danych\", \"Rozwiązanie AI/ML\", \"Inne\"]\n",
        "            )\n",
        "            timeline = st.selectbox(\n",
        "                \"Oczekiwany Termin\", [\"1-2 miesiące\", \"3-4 miesiące\", \"5-6 miesięcy\", \"6+ miesięcy\"]\n",
        "            )\n",
        "\n",
        "        with col2:\n",
        "            budget_range = st.selectbox(\n",
        "                \"Zakres Budżetu\",\n",
        "                [\"10k-25k zł\", \"25k-50k zł\", \"50k-100k zł\", \"100k+ zł\"]\n",
        "            )\n",
        "            priority = st.selectbox( \"Priorytet Projektu\", [\"Wysoki\", \"Średni\", \"Niski\"] )\n",
        "\n",
        "        tech_requirements = st.text_area(\n",
        "            \"Wymagania Techniczne (opcjonalnie)\", help=\"Szczególne wymagania techniczne lub preferencje\" )\n",
        "\n",
        "        special_considerations = st.text_area(\n",
        "            \"Specjalne Uwagi (opcjonalnie)\",\n",
        "            help=\"Dodatkowe informacje lub specjalne wymagania\"\n",
        "        )\n",
        "\n",
        "        submitted = st.form_submit_button(\"Analizuj Projekt\")\n",
        "\n",
        "    if submitted and project_name and project_description:\n",
        "        try:\n",
        "          # Set OpenAI key\n",
        "          set_openai_key(st.session_state.api_key)\n",
        "\n",
        "          # Create agents\n",
        "          ceo = Agent(\n",
        "              name=\"Dyrektor Projektu\",\n",
        "              description=\"Jesteś CEO wielu firm w przeszłości i masz duże doświadczenie w ocenie projektów i podejmowaniu strategicznych decyzji.\",\n",
        "              instructions=\"\"\"\n",
        "              Jesteś doświadczonym CEO, który ocenia projekty. Postępuj ściśle według tych kroków:\n",
        "\n",
        "              1. NAJPIERW użyj narzędzia AnalyzeProjectRequirements z:\n",
        "                  - project_name: Nazwa z szczegółów projektu\n",
        "                  - project_description: Pełny opis projektu\n",
        "                  - project_type: Typ projektu (Aplikacja webowa, Aplikacja mobilna, itp.)\n",
        "                  - budget_range: Określony zakres budżetu\n",
        "\n",
        "              2. POCZEKAJ na zakończenie analizy przed kontynuacją.\n",
        "\n",
        "              3. Przejrzyj wyniki analizy i przedstaw strategiczne rekomendacje.\n",
        "              \"\"\",\n",
        "              tools=[AnalyzeProjectRequirements],\n",
        "              api_headers=api_headers,\n",
        "              temperature=0.7,\n",
        "              max_prompt_tokens=25000\n",
        "          )\n",
        "\n",
        "          cto = Agent(\n",
        "              name=\"Architekt Techniczny\",\n",
        "              description=\"Starszy architekt techniczny z głęboką wiedzą w projektowaniu systemów.\",\n",
        "              instructions=\"\"\"\n",
        "              Jesteś architektem technicznym. Postępuj ściśle według tych kroków:\n",
        "\n",
        "              1. POCZEKAJ na zakończenie analizy projektu przez CEO.\n",
        "\n",
        "              2. Użyj narzędzia CreateTechnicalSpecification z:\n",
        "                  - architecture_type: Wybierz spośród monolityczna/mikroserwisy/serverless/hybrydowa\n",
        "                  - core_technologies: Lista głównych technologii oddzielonych przecinkami\n",
        "                  - scalability_requirements: Wybierz wysoka/średnia/niska na podstawie potrzeb projektu\n",
        "\n",
        "              3. Przejrzyj specyfikację techniczną i przedstaw dodatkowe rekomendacje.\n",
        "              \"\"\",\n",
        "              tools=[CreateTechnicalSpecification],\n",
        "              api_headers=api_headers,\n",
        "              temperature=0.5,\n",
        "              max_prompt_tokens=25000\n",
        "          )\n",
        "\n",
        "          product_manager = Agent(\n",
        "                              name=\"Kierownik Produktu\",\n",
        "                              description=\"Doświadczony kierownik produktu skupiający się na doskonałości dostarczania.\",\n",
        "                              instructions=\"\"\"\n",
        "                              - Zarządzaj zakresem i harmonogramem projektu, przedstawiając mapę drogową projektu\n",
        "                              - Zdefiniuj wymagania produktu i powinieneś zaproponować potencjalne produkty i funkcje, które można zbudować dla startupu\n",
        "                              \"\"\",\n",
        "                              api_headers=api_headers,\n",
        "                              temperature=0.4,\n",
        "                              max_prompt_tokens=25000\n",
        "                          )\n",
        "\n",
        "          developer = Agent(\n",
        "              name=\"Główny Programista\",\n",
        "              description=\"Starszy programista z doświadczeniem full-stack.\",\n",
        "              instructions=\"\"\"\n",
        "              - Zaplanuj implementację techniczną\n",
        "              - Przedstaw szacunki nakładu pracy\n",
        "              - Oceń wykonalność techniczną\n",
        "              \"\"\",\n",
        "              api_headers=api_headers,\n",
        "              temperature=0.3,\n",
        "              max_prompt_tokens=25000\n",
        "          )\n",
        "\n",
        "          client_manager = Agent(\n",
        "              name=\"Kierownik ds. Sukcesu Klienta\",\n",
        "              description=\"Doświadczony kierownik ds. klienta skupiający się na dostarczaniu projektu.\",\n",
        "              instructions=\"\"\"\n",
        "              - Zapewnij satysfakcję klienta\n",
        "              - Zarządzaj oczekiwaniami\n",
        "              - Obsługuj feedback\n",
        "              \"\"\",\n",
        "              api_headers=api_headers,\n",
        "              temperature=0.6,\n",
        "              max_prompt_tokens=25000\n",
        "          )\n",
        "\n",
        "          # Utwórz agencję\n",
        "          agency = Agency(\n",
        "              [\n",
        "                  ceo, cto, product_manager, developer, client_manager,\n",
        "                  [ceo, cto],\n",
        "                  [ceo, product_manager],\n",
        "                  [ceo, developer],\n",
        "                  [ceo, client_manager],\n",
        "                  [cto, developer],\n",
        "                  [product_manager, developer],\n",
        "                  [product_manager, client_manager]\n",
        "              ],\n",
        "              async_mode='threading',\n",
        "              shared_files='shared_files'\n",
        "          )\n",
        "\n",
        "          # Przygotuj informacje o projekcie\n",
        "          project_info = {\n",
        "              \"name\": project_name,\n",
        "              \"description\": project_description,\n",
        "              \"type\": project_type,\n",
        "              \"timeline\": timeline,\n",
        "              \"budget\": budget_range,\n",
        "              \"priority\": priority,\n",
        "              \"technical_requirements\": tech_requirements,\n",
        "              \"special_considerations\": special_considerations\n",
        "          }\n",
        "\n",
        "          st.session_state.messages.append({\"role\": \"user\", \"content\": str(project_info)})\n",
        "          # Utwórz zakładki i uruchom analizę\n",
        "          with st.spinner(\"Agencja Usług AI analizuje Twój projekt...\"):\n",
        "              try:\n",
        "                  # Pobierz analizę od każdego agenta używając agency.get_completion()\n",
        "                  ceo_response = agency.get_completion(\n",
        "                      message=f\"\"\"Przeanalizuj ten projekt używając narzędzia AnalyzeProjectRequirements:\n",
        "                      Nazwa Projektu: {project_name}\n",
        "                      Opis Projektu: {project_description}\n",
        "                      Typ Projektu: {project_type}\n",
        "                      Zakres Budżetu: {budget_range}\n",
        "\n",
        "                      Użyj dokładnie tych wartości z narzędziem i poczekaj na wyniki analizy.\"\"\",\n",
        "                      recipient_agent=ceo\n",
        "                  )\n",
        "\n",
        "                  cto_response = agency.get_completion(\n",
        "                      message=f\"\"\"Przejrzyj analizę projektu i utwórz specyfikacje techniczne używając narzędzia CreateTechnicalSpecification.\n",
        "                      Wybierz najbardziej odpowiednie:\n",
        "                      - architecture_type (monolityczna/mikroserwisy/serverless/hybrydowa)\n",
        "                      - core_technologies (lista oddzielona przecinkami)\n",
        "                      - scalability_requirements (wysoka/średnia/niska)\n",
        "\n",
        "                      Oprzyj swoje wybory na wymaganiach projektu i analizie.\"\"\",\n",
        "                      recipient_agent=cto\n",
        "                  )\n",
        "\n",
        "                  pm_response = agency.get_completion(\n",
        "                      message=f\"Przeanalizuj aspekty zarządzania projektem: {str(project_info)}\",\n",
        "                      recipient_agent=product_manager,\n",
        "                      additional_instructions=\"Skup się na dopasowaniu produktu do rynku i rozwoju mapy drogowej, oraz koordynuj z zespołami technicznymi i marketingowymi.\"\n",
        "                  )\n",
        "\n",
        "                  developer_response = agency.get_completion(\n",
        "                      message=f\"Przeanalizuj implementację techniczną na podstawie specyfikacji CTO: {str(project_info)}\",\n",
        "                      recipient_agent=developer,\n",
        "                      additional_instructions=\"Przedstaw szczegóły implementacji technicznej, optymalny stos technologiczny, który byłby używany, włącznie z kosztami usług chmurowych (jeśli są) i opinią o wykonalności, oraz koordynuj z kierownikiem produktu i CTO, aby zbudować wymagane produkty dla startupu.\"\n",
        "                  )\n",
        "\n",
        "                  client_response = agency.get_completion(\n",
        "                      message=f\"Przeanalizuj aspekty sukcesu klienta: {str(project_info)}\",\n",
        "                      recipient_agent=client_manager,\n",
        "                      additional_instructions=\"Przedstaw szczegółową strategię wejścia na rynek i plan pozyskiwania klientów, oraz koordynuj z kierownikiem produktu.\"\n",
        "                  )\n",
        "\n",
        "                  # Utwórz zakładki dla różnych analiz\n",
        "                  tabs = st.tabs([\n",
        "                      \"Analiza Projektu CEO\",\n",
        "                      \"Specyfikacja Techniczna CTO\",\n",
        "                      \"Plan Kierownika Produktu\",\n",
        "                      \"Implementacja Programisty\",\n",
        "                      \"Strategia Sukcesu Klienta\"\n",
        "                  ])\n",
        "\n",
        "                  with tabs[0]:\n",
        "                      st.markdown(\"## Analiza Strategiczna CEO\")\n",
        "                      st.markdown(ceo_response)\n",
        "                      st.session_state.messages.append({\"role\": \"assistant\", \"content\": ceo_response})\n",
        "\n",
        "                  with tabs[1]:\n",
        "                      st.markdown(\"## Specyfikacja Techniczna CTO\")\n",
        "                      st.markdown(cto_response)\n",
        "                      st.session_state.messages.append({\"role\": \"assistant\", \"content\": cto_response})\n",
        "\n",
        "                  with tabs[2]:\n",
        "                      st.markdown(\"## Plan Kierownika Produktu\")\n",
        "                      st.markdown(pm_response)\n",
        "                      st.session_state.messages.append({\"role\": \"assistant\", \"content\": pm_response})\n",
        "\n",
        "                  with tabs[3]:\n",
        "                      st.markdown(\"## Plan Rozwoju Głównego Programisty\")\n",
        "                      st.markdown(developer_response)\n",
        "                      st.session_state.messages.append({\"role\": \"assistant\", \"content\": developer_response})\n",
        "\n",
        "                  with tabs[4]:\n",
        "                      st.markdown(\"## Strategia Sukcesu Klienta\")\n",
        "                      st.markdown(client_response)\n",
        "                      st.session_state.messages.append({\"role\": \"assistant\", \"content\": client_response})\n",
        "\n",
        "              except Exception as e:\n",
        "                  st.error(f\"Błąd podczas analizy: {str(e)}\")\n",
        "                  st.error(\"Sprawdź swoje dane wejściowe i klucz API, a następnie spróbuj ponownie.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Błąd podczas analizy: {str(e)}\")\n",
        "            st.error(\"Sprawdź swój klucz API i spróbuj ponownie.\")\n",
        "\n",
        "    # Dodaj zarządzanie historią w pasku bocznym\n",
        "    with st.sidebar:\n",
        "        st.subheader(\"Opcje\")\n",
        "        if st.checkbox(\"Pokaż Historię Analiz\"):\n",
        "            for message in st.session_state.messages:\n",
        "                with st.chat_message(message[\"role\"]):\n",
        "                    st.markdown(message[\"content\"])\n",
        "\n",
        "        if st.button(\"Wyczyść Historię\"):\n",
        "            st.session_state.messages = []\n",
        "            st.rerun()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djwf-B88MeEK",
        "outputId": "c843f0d4-278d-4785-92b9-566bf8728262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting muh_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kod przedstawia aplikację Streamlit służącą do analizy i zarządzania projektami IT przy użyciu agentów AI. Składa się z następujących kluczowych elementów:\n",
        "\n",
        "1. Klasa `AnalyzeProjectRequirements` - narzędzie do analizy wymagań projektu:\n",
        "- Przyjmuje nazwę, opis, typ projektu i zakres budżetu\n",
        "- Zapisuje wyniki analizy w pamięci współdzielonej\n",
        "- Ocenia złożoność, harmonogram i wykonalność budżetową projektu\n",
        "\n",
        "2. Klasa `CreateTechnicalSpecification` - narzędzie do tworzenia specyfikacji technicznej:\n",
        "- Określa typ architektury, główne technologie i wymagania skalowalności\n",
        "- Działa na podstawie wcześniejszej analizy projektu\n",
        "- Generuje szczegółową specyfikację techniczną\n",
        "\n",
        "3. Funkcja `init_session_state()` inicjalizuje zmienne sesji Streamlit do przechowywania wiadomości i klucza API.\n",
        "\n",
        "4. Główna funkcja `main()`:\n",
        "- Konfiguruje interfejs użytkownika Streamlit\n",
        "- Zawiera formularz do wprowadzania szczegółów projektu\n",
        "- Tworzy i konfiguruje pięciu agentów:\n",
        "  - Dyrektor Projektu (CEO)\n",
        "  - Architekt Techniczny (CTO)\n",
        "  - Kierownik Produktu\n",
        "  - Główny Programista\n",
        "  - Kierownik ds. Sukcesu Klienta\n",
        "\n",
        "5. Logika przetwarzania formularza:\n",
        "- Sprawdza poprawność wprowadzonych danych\n",
        "- Tworzy agencję łączącą wszystkich agentów\n",
        "- Uruchamia analizę projektu przez każdego agenta\n",
        "- Wyświetla wyniki w zakładkach interfejsu\n",
        "\n",
        "6. Panel boczny zawiera:\n",
        "- Pole do wprowadzania klucza API OpenAI\n",
        "- Opcje wyświetlania i czyszczenia historii analiz\n",
        "\n",
        "System wykorzystuje architekturę wieloagentową do kompleksowej analizy projektów IT z różnych perspektyw biznesowych i technicznych."
      ],
      "metadata": {
        "id": "z44cVGKxRmGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(Agency)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "9vgUnHljW1N4",
        "outputId": "7edfc9cb-422d-4106-e66d-4862b9eb5cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Agency' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5dad611dc7bb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Agency' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Biegnij Forrest"
      ],
      "metadata": {
        "id": "RRLv1BtmMfn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run muh_app.py --server.address=localhost  &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDduqGyeQ-34",
        "outputId": "89a168a6-535d-4e02-904a-64f4eb378ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.75.128.191\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://wicked-berries-tap.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta sekwencja komend uruchamia kilka procesów:\n",
        "\n",
        "1. `streamlit run muh_app.py --server.address=localhost`\n",
        "- Uruchamia aplikację Streamlit\n",
        "- Parametr `--server.address=localhost` określa, że serwer ma być dostępny tylko lokalnie\n",
        "- `&>/content/logs.txt` przekierowuje wszystkie komunikaty (standardowe wyjście i błędy) do pliku logs.txt\n",
        "- `&` na końcu uruchamia proces w tle\n",
        "\n",
        "2. `npx localtunnel --port 8501`\n",
        "- Tworzy tunel przez localtunnel do portu 8501 (domyślny port Streamlit)\n",
        "- Pozwala na dostęp do lokalnej aplikacji z internetu\n",
        "- Wygeneruje publiczny URL dostępowy\n",
        "\n",
        "3. `curl ipv4.icanhazip.com`\n",
        "- Pobiera publiczny adres IP komputera\n",
        "- Może być przydatne do weryfikacji połączenia lub konfiguracji\n",
        "\n",
        "Znak `&` pomiędzy komendami sprawia, że wszystkie procesy uruchamiają się równolegle."
      ],
      "metadata": {
        "id": "3Fw8vO-6WW10"
      }
    }
  ]
}