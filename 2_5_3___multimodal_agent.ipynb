{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Qese0zMFQ94z",
        "tE_2Q3QqRT7S",
        "aU9a_R17Sglq"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kapamawi/AI/blob/main/2_5_3___multimodal_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "vm-6AOhRSmAs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBShg_fgLr28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165942bc-7b46-4bbc-d28c-db4547ba181e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.0/306.0 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU llama-index-callbacks-arize-phoenix llama-parse llama-index-llms-openai llama-index-embeddings-openai llama-index-multi-modal-llms-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod instaluje kilka pakietów Pythona związanych z LlamaIndex - narzędziem do pracy z dużymi modelami językowymi i danymi:\n",
        "\n",
        "`llama-index-callbacks-arize-phoenix` - moduł do integracji z platformą Arize Phoenix, która służy do monitorowania i analizowania modeli ML\n",
        "\n",
        "`llama-parse` - parser dokumentów, który przekształca różne formaty (PDF, HTML itp.) na ustrukturyzowane dane\n",
        "\n",
        "`llama-index-llms-openai` - adapter do wykorzystania modeli językowych OpenAI w LlamaIndex\n",
        "\n",
        "`llama-index-embeddings-openai` - moduł do tworzenia embedingów (wektorowych reprezentacji tekstu) przy użyciu API OpenAI\n",
        "\n",
        "`llama-index-multi-modal-llms-openai` - rozszerzenie umożliwiające pracę z modelami multimodalnymi OpenAI, które potrafią przetwarzać zarówno tekst jak i obrazy\n",
        "\n",
        "Flaga `-q` wycisza standardowe komunikaty instalacyjne, a `-U` wymusza aktualizację do najnowszych wersji pakietów."
      ],
      "metadata": {
        "id": "5OdrnNbABKOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import re\n",
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "from google.colab import userdata\n",
        "from pprint import pp as ppr\n",
        "\n",
        "# Third-party imports\n",
        "from llama_parse import LlamaParse\n",
        "\n",
        "# LlamaIndex core imports\n",
        "from llama_index.core import Settings, StorageContext, VectorStoreIndex, load_index_from_storage\n",
        "from llama_index.core.schema import TextNode, ImageNode, NodeWithScore, MetadataMode\n",
        "from llama_index.core.query_engine import CustomQueryEngine, SimpleMultiModalQueryEngine\n",
        "from llama_index.core.retrievers import BaseRetriever\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.core.base.response.schema import Response\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core import set_global_handler\n",
        "\n",
        "# LlamaIndex service-specific imports\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "217EoNM7OC-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod zawiera importy niezbędnych bibliotek i modułów:\n",
        "\n",
        "Ze standardowej biblioteki Pythona:\n",
        "- `os` - operacje na systemie operacyjnym i ścieżkach\n",
        "- `re` - obsługa wyrażeń regularnych\n",
        "- `deepcopy` - tworzenie głębokich kopii obiektów\n",
        "- `Path` - obiektowa obsługa ścieżek do plików\n",
        "- `Optional` - typ dla wartości opcjonalnych\n",
        "- `userdata` - dostęp do danych użytkownika w Google Colab\n",
        "- `ppr` - funkcja do ładnego wyświetlania struktur danych\n",
        "\n",
        "Z zewnętrznych bibliotek:\n",
        "- `LlamaParse` - narzędzie do parsowania dokumentów\n",
        "\n",
        "Z głównego modułu LlamaIndex importowane są podstawowe komponenty:\n",
        "- `Settings`, `StorageContext` - konfiguracja i zarządzanie przechowywaniem\n",
        "- `VectorStoreIndex` - indeks wektorowy dokumentów\n",
        "- `load_index_from_storage` - wczytywanie zapisanego indeksu\n",
        "- Klasy do obsługi różnych typów węzłów (`TextNode`, `ImageNode`)\n",
        "- Komponenty do budowy silników zapytań i ich obsługi\n",
        "- System promptów i odpowiedzi\n",
        "- Narzędzia do tworzenia agentów\n",
        "\n",
        "Ze specyficznych modułów LlamaIndex:\n",
        "- Integracja z OpenAI (modele językowe, embedingi, modele multimodalne)\n",
        "\n",
        "Na końcu włączany jest `nest_asyncio`, który umożliwia zagnieżdżone pętle asynchroniczne w Jupyterze/Colab."
      ],
      "metadata": {
        "id": "KgxX-d2SBvyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "  model1 = \"gpt-4o\"\n",
        "  model2 = \"text-embedding-3-large\"\n",
        "  temperature = 0.1\n",
        "  chunksize = 1024"
      ],
      "metadata": {
        "id": "OghtAizdOp_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trace the whole thing\n",
        "PHOENIX_API_KEY = userdata.get('arize')\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
        "set_global_handler(\n",
        "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
        ")\n",
        "\n",
        "\n",
        "# Using OpenAI API for embeddings/llms\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openaivision')\n",
        "\n",
        "# API access to llama-cloud\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = userdata.get('llamaparse')"
      ],
      "metadata": {
        "id": "-_KguTl_OxY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten fragment kodu konfiguruje śledzenie (tracing) i klucze API dla różnych usług:\n",
        "\n",
        "1. Konfiguracja Arize Phoenix do śledzenia:\n",
        "- Pobiera klucz API Arize z danych użytkownika\n",
        "- Ustawia go jako nagłówek dla eksportera OTEL (OpenTelemetry)\n",
        "- Konfiguruje globalny handler do wysyłania śladów na llamatrace.com\n",
        "\n",
        "2. Ustawia klucz API OpenAI:\n",
        "- Pobiera klucz dostępu do OpenAI Vision z danych użytkownika\n",
        "- Zapisuje go jako zmienną środowiskową OPENAI_API_KEY\n",
        "- Ten klucz będzie używany do embedingów i modeli językowych\n",
        "\n",
        "3. Konfiguruje dostęp do Llama Cloud:\n",
        "- Pobiera klucz API dla usługi llama-parse\n",
        "- Zapisuje go jako zmienną środowiskową LLAMA_CLOUD_API_KEY\n",
        "\n",
        "Wszystkie klucze są pobierane bezpiecznie z danych użytkownika w Google Colab zamiast być zapisane bezpośrednio w kodzie. Te ustawienia umożliwiają monitorowanie działania aplikacji oraz dostęp do zewnętrznych API potrzebnych do przetwarzania dokumentów i generowania odpowiedzi."
      ],
      "metadata": {
        "id": "cMe05GiICQRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm = OpenAI(model= CFG.model1)\n",
        "Settings.llm = llm\n",
        "\n",
        "embed_model = OpenAIEmbedding(model = CFG.model2)\n",
        "Settings.embed_model = embed_model\n"
      ],
      "metadata": {
        "id": "F5hyajCYRDvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod konfiguruje dwa kluczowe komponenty w LlamaIndex:\n",
        "\n",
        "1. Model językowy (LLM):\n",
        "- Tworzy instancję modelu OpenAI, używając wartości `model1` z konfiguracji\n",
        "- Ustawia ten model jako globalny LLM w ustawieniach\n",
        "\n",
        "2. Model do tworzenia embedingów:\n",
        "- Tworzy instancję modelu OpenAIEmbedding, używając wartości `model2` z konfiguracji\n",
        "- Ustawia ten model jako globalny model embedingów w ustawieniach\n",
        "\n",
        "Te globalne ustawienia sprawiają, że wszystkie komponenty LlamaIndex będą domyślnie używać tych samych modeli, zapewniając spójność w całej aplikacji. Embedingi służą do przekształcania tekstu na wektory liczbowe, co umożliwia wyszukiwanie semantyczne, a model językowy jest używany do generowania odpowiedzi."
      ],
      "metadata": {
        "id": "wT1bSkSeCRQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "5HFEsaRcSpVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_page_number(file_name):\n",
        "    match = re.search(r\"-page-(\\d+)\\.jpg$\", str(file_name))\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return 0\n"
      ],
      "metadata": {
        "id": "X6d9P7muSs1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta funkcja wydobywa numer strony z nazwy pliku:\n",
        "\n",
        "- Przyjmuje parametr `file_name` (nazwa pliku)\n",
        "- Używa wyrażenia regularnego do znalezienia wzorca \"-page-X.jpg\", gdzie X to liczba\n",
        "- `r\"-page-(\\d+)\\.jpg$\"` to wzorzec, który:\n",
        "  - Szuka tekstu \"-page-\"\n",
        "  - Następnie szuka jednej lub więcej cyfr (`\\d+`)\n",
        "  - Kończy się na \".jpg\" (`\\.jpg$`)\n",
        "- Jeśli wzorzec zostanie znaleziony, funkcja zwraca znalezioną liczbę jako integer\n",
        "- Jeśli wzorzec nie zostanie znaleziony, zwraca 0\n"
      ],
      "metadata": {
        "id": "o8pnaokBCxsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_sorted_image_files(image_dir):\n",
        "    \"\"\"Get image files sorted by page.\"\"\"\n",
        "    raw_files = [f for f in list(Path(image_dir).iterdir()) if f.is_file()]\n",
        "    sorted_files = sorted(raw_files, key=get_page_number)\n",
        "    return sorted_files\n"
      ],
      "metadata": {
        "id": "lqyD3ix0SruD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta funkcja sortuje pliki obrazów według numeru strony:\n",
        "\n",
        "- Przyjmuje parametr `image_dir` - ścieżkę do katalogu z obrazami\n",
        "- Używa `Path(image_dir).iterdir()` do iteracji po zawartości katalogu\n",
        "- Tworzy listę zawierającą tylko pliki (pomija podkatalogi) poprzez `is_file()`\n",
        "- Sortuje listę plików używając wcześniej zdefiniowanej funkcji `get_page_number` jako klucza sortowania\n",
        "- Zwraca posortowaną listę plików\n"
      ],
      "metadata": {
        "id": "6b2o7uXHC7E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# attach image metadata to the text nodes\n",
        "def get_text_nodes(docs, image_dir=None, json_dicts=None):\n",
        "    \"\"\"Split docs into nodes, by separator.\"\"\"\n",
        "    nodes = []\n",
        "\n",
        "    image_files = _get_sorted_image_files(image_dir) if image_dir is not None else None\n",
        "    md_texts = [d[\"md\"] for d in json_dicts] if json_dicts is not None else None\n",
        "\n",
        "    doc_chunks = [c for d in docs for c in d.text.split(\"---\")]\n",
        "    for idx, doc_chunk in enumerate(doc_chunks):\n",
        "        chunk_metadata = {\"page_num\": idx + 1}\n",
        "        if image_files is not None:\n",
        "            image_file = image_files[idx]\n",
        "            chunk_metadata[\"image_path\"] = str(image_file)\n",
        "        if md_texts is not None:\n",
        "            chunk_metadata[\"parsed_text_markdown\"] = md_texts[idx]\n",
        "        chunk_metadata[\"parsed_text\"] = doc_chunk\n",
        "        node = TextNode(\n",
        "            text=\"\",\n",
        "            metadata=chunk_metadata,\n",
        "        )\n",
        "        nodes.append(node)\n",
        "\n",
        "    return nodes"
      ],
      "metadata": {
        "id": "--GfuGO8SwWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta funkcja przetwarza dokumenty na węzły tekstu z metadanymi:\n",
        "\n",
        "- Przyjmuje parametry:\n",
        "  - `docs` - dokumenty do przetworzenia\n",
        "  - `image_dir` - opcjonalny katalog z obrazami\n",
        "  - `json_dicts` - opcjonalny słownik z tekstami w formacie Markdown\n",
        "\n",
        "- Działanie:\n",
        "  - Jeśli podano `image_dir`, pobiera posortowane pliki obrazów\n",
        "  - Jeśli podano `json_dicts`, wyciąga teksty Markdown\n",
        "  - Dzieli każdy dokument na części używając separatora \"---\"\n",
        "  - Dla każdej części tworzy metadane zawierające:\n",
        "    - Numer strony\n",
        "    - Ścieżkę do obrazu (jeśli dostępna)\n",
        "    - Tekst w formacie Markdown (jeśli dostępny)\n",
        "    - Oryginalny tekst części\n",
        "  - Tworzy węzeł `TextNode` z pustym tekstem i metadanymi\n",
        "  - Dodaje węzeł do listy\n",
        "\n",
        "- Zwraca listę utworzonych węzłów\n",
        "\n",
        "Funkcja służy do łączenia tekstu z odpowiadającymi mu obrazami i dodatkowymi metadanymi, zachowując informację o numeracji stron."
      ],
      "metadata": {
        "id": "b2XQLgRxC9w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nodes(docs):\n",
        "    \"\"\"Split docs into nodes, by separator.\"\"\"\n",
        "    nodes = []\n",
        "    for doc in docs:\n",
        "        doc_chunks = doc.text.split(\"\\n---\\n\")\n",
        "        for doc_chunk in doc_chunks:\n",
        "            node = TextNode(\n",
        "                text=doc_chunk,\n",
        "                metadata=deepcopy(doc.metadata),\n",
        "            )\n",
        "            nodes.append(node)\n",
        "\n",
        "    return nodes"
      ],
      "metadata": {
        "id": "5dz2gcWSUriB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta funkcja przetwarza dokumenty na węzły tekstu:\n",
        "\n",
        "- Przyjmuje listę dokumentów (`docs`)\n",
        "- Dla każdego dokumentu:\n",
        "  - Dzieli jego tekst na części używając separatora \"\\n---\\n\"\n",
        "  - Dla każdej części tworzy nowy węzeł `TextNode` zawierający:\n",
        "    - Tekst danej części\n",
        "    - Głęboką kopię metadanych oryginalnego dokumentu (używając `deepcopy`)\n",
        "  - Dodaje utworzony węzeł do listy\n",
        "- Zwraca listę wszystkich utworzonych węzłów\n",
        "\n",
        "W przeciwieństwie do poprzedniej funkcji `get_text_nodes`, ta wersja:\n",
        "- Używa tekstu bezpośrednio w węźle zamiast w metadanych\n",
        "- Zachowuje oryginalne metadane dokumentu\n",
        "- Ma prostszą strukturę bez obsługi obrazów i Markdown\n",
        "- Używa innego separatora (\"\\n---\\n\" zamiast \"---\")"
      ],
      "metadata": {
        "id": "F64OJ9RKDD_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MultimodalQueryEngine(CustomQueryEngine):\n",
        "    \"\"\"Custom multimodal Query Engine.\n",
        "\n",
        "    Takes in a retriever to retrieve a set of document nodes.\n",
        "    Also takes in a prompt template and multimodal model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    qa_prompt: PromptTemplate\n",
        "    retriever: BaseRetriever\n",
        "    multi_modal_llm: OpenAIMultiModal\n",
        "\n",
        "    def __init__(self, qa_prompt: Optional[PromptTemplate] = None, **kwargs) -> None:\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super().__init__(qa_prompt=qa_prompt or QA_PROMPT, **kwargs)\n",
        "\n",
        "    def custom_query(self, query_str: str):\n",
        "        # retrieve text nodes\n",
        "        nodes = self.retriever.retrieve(query_str)\n",
        "        # create ImageNode items from text nodes\n",
        "        image_nodes = [\n",
        "            NodeWithScore(node=ImageNode(image_path=n.metadata[\"image_path\"]))\n",
        "            for n in nodes\n",
        "        ]\n",
        "\n",
        "        # create context string from text nodes, dump into the prompt\n",
        "        context_str = \"\\n\\n\".join(\n",
        "            [r.get_content(metadata_mode=MetadataMode.LLM) for r in nodes]\n",
        "        )\n",
        "        fmt_prompt = self.qa_prompt.format(context_str=context_str, query_str=query_str)\n",
        "\n",
        "        # synthesize an answer from formatted text and images\n",
        "        llm_response = self.multi_modal_llm.complete(\n",
        "            prompt=fmt_prompt,\n",
        "            image_documents=[image_node.node for image_node in image_nodes],\n",
        "        )\n",
        "        return Response(\n",
        "            response=str(llm_response),\n",
        "            source_nodes=nodes,\n",
        "            metadata={\"text_nodes\": text_nodes, \"image_nodes\": image_nodes},\n",
        "        )\n",
        "\n",
        "#         return response"
      ],
      "metadata": {
        "id": "DB5YlBe0UiNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta klasa implementuje silnik zapytań obsługujący dane multimodalne (tekst i obrazy):\n",
        "\n",
        "Główne komponenty:\n",
        "- `qa_prompt` - szablon promptu do zadawania pytań\n",
        "- `retriever` - moduł do wyszukiwania odpowiednich dokumentów\n",
        "- `multi_modal_llm` - model językowy obsługujący zarówno tekst jak i obrazy\n",
        "\n",
        "Metoda `custom_query`:\n",
        "- Przyjmuje zapytanie tekstowe\n",
        "- Wyszukuje odpowiednie węzły tekstowe\n",
        "- Tworzy węzły obrazów na podstawie ścieżek zapisanych w metadanych węzłów tekstowych\n",
        "- Łączy zawartość tekstową węzłów w jeden kontekst\n",
        "- Formatuje prompt używając kontekstu i zapytania\n",
        "- Generuje odpowiedź używając modelu multimodalnego, który analizuje zarówno tekst jak i obrazy\n",
        "- Zwraca odpowiedź w formie obiektu `Response` zawierającego:\n",
        "  - Wygenerowaną odpowiedź tekstową\n",
        "  - Użyte węzły źródłowe\n",
        "  - Metadane z użytymi węzłami tekstowymi i obrazowymi\n"
      ],
      "metadata": {
        "id": "lltUEu3mDZqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "Qese0zMFQ94z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir data_images\n",
        "!wget \"https://static.conocophillips.com/files/2023-conocophillips-aim-presentation.pdf\" -O data/conocophillips.pdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMiPNMI-Q-re",
        "outputId": "a90f3763-34e4-4891-8d37-c4a8db2e4d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-29 08:15:50--  https://static.conocophillips.com/files/2023-conocophillips-aim-presentation.pdf\n",
            "Resolving static.conocophillips.com (static.conocophillips.com)... 13.249.126.4, 13.249.126.43, 13.249.126.99, ...\n",
            "Connecting to static.conocophillips.com (static.conocophillips.com)|13.249.126.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41895745 (40M) [application/pdf]\n",
            "Saving to: ‘data/conocophillips.pdf’\n",
            "\n",
            "data/conocophillips 100%[===================>]  39.95M  38.8MB/s    in 1.0s    \n",
            "\n",
            "2024-11-29 08:15:52 (38.8 MB/s) - ‘data/conocophillips.pdf’ saved [41895745/41895745]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse text / img"
      ],
      "metadata": {
        "id": "tE_2Q3QqRT7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parser_text = LlamaParse(result_type=\"text\")\n",
        "parser_gpt4o = LlamaParse(result_type=\"markdown\", gpt4o_mode=True)\n"
      ],
      "metadata": {
        "id": "SNXldeb4RW24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod tworzy dwie instancje parsera LlamaParse:\n",
        "\n",
        "`parser_text`:\n",
        "- Ustawiony na zwracanie wyniku jako czysty tekst\n",
        "- Nie używa specjalnego trybu GPT-4\n",
        "- Służy do podstawowego parsowania dokumentów\n",
        "\n",
        "`parser_gpt4o`:\n",
        "- Ustawiony na zwracanie wyniku w formacie Markdown\n",
        "- Ma włączony specjalny tryb `gpt4o_mode`\n",
        "- Będzie generował bardziej ustrukturyzowany wynik, prawdopodobnie zoptymalizowany pod kątem współpracy z GPT-4"
      ],
      "metadata": {
        "id": "DpNvVX62Dxf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Parsing text...\")\n",
        "docs_text = parser_text.load_data(\"data/conocophillips.pdf\")\n",
        "print(f\"Parsing PDF file...\")\n",
        "md_json_objs = parser_gpt4o.get_json_result(\"data/conocophillips.pdf\")\n",
        "md_json_list = md_json_objs[0][\"pages\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLIZpChgRY_I",
        "outputId": "b8c27fa3-a015-46ea-c767-fb661f1f7579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing text...\n",
            "Started parsing the file under job_id 6dcc9859-d381-446f-b3b1-ec428af777cc\n",
            "Parsing PDF file...\n",
            "Started parsing the file under job_id affd3516-6466-4de8-a372-fbc4f7d6342b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod parsuje plik PDF na dwa różne sposoby:\n",
        "\n",
        "1. `docs_text = parser_text.load_data(\"data/conocophillips.pdf\")`\n",
        "- Wczytuje PDF używając pierwszego parsera (text)\n",
        "- Tworzy prostą reprezentację tekstową dokumentu\n",
        "- Zapisuje wynik w `docs_text`\n",
        "\n",
        "2. `md_json_objs = parser_gpt4o.get_json_result(\"data/conocophillips.pdf\")`\n",
        "- Parsuje ten sam PDF używając drugiego parsera (markdown + gpt4o)\n",
        "- Zwraca wynik w formacie JSON\n",
        "- `md_json_list = md_json_objs[0][\"pages\"]` wyciąga listę stron z pierwszego obiektu w wynikach"
      ],
      "metadata": {
        "id": "UaqWkYRiED3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(md_json_list[2][\"md\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tSVJGBXRsZJ",
        "outputId": "6d521780-09a0-48a1-83fb-63fcb0e29d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Cautionary Statement\n",
            "\n",
            "This presentation provides management’s current operational plan for ConocoPhillips over roughly the next decade, for the assets currently in our portfolio, and is subject to multiple assumptions, including, unless otherwise specifically noted:\n",
            "\n",
            "- an oil price of $60/BBL West Texas Intermediate in 2022 dollars, escalating at 2.25% annually;\n",
            "- an oil price of $65/BBL Brent in 2022 dollars, escalating at 2.25% annually;\n",
            "- a gas price of $3.75/MMBTU Henry Hub in 2022 dollars, escalating at 2.25% annually;\n",
            "- an international gas price of $8/MMBTU Title Transfer Facility & Japan Korea Marker in 2022 dollars, escalating at 2.25% annually;\n",
            "- cost and capital escalation in line with price escalation; planning case of $60/BBL WTI assumes capital de-escalation from levels observed in 2022;\n",
            "- all production compound annual growth rates (CAGR) are calculated for the 10-year period 2023 – 2032;\n",
            "- inclusion of carbon tax in the cash flow forecasts for assets where a tax is currently assessed. If no carbon tax exists for the asset, it is not included in the cash flow forecasts;\n",
            "- Cost of Supply displayed in WTI, includes carbon tax where carbon policy exists and a proxy carbon price for assets without existing carbon policies. Please refer to the Cost of Supply definition in the Appendix for additional information on how carbon costs are included in the Cost of Supply calculation.\n",
            "\n",
            "As a result, this presentation contains forward-looking statements as defined under the federal securities laws. Forward-looking statements relate to future events, plans and anticipated results of operations, business strategies, and other aspects of our operations or operating results. Graphics that project into a future date constitute forward-looking statements. Also, words and phrases such as \"anticipate,\" \"estimate,\" \"believe,\" \"budget,\" \"continue,\" \"could,\" \"intend,\" \"may,\" \"plan,\" \"potential,\" \"predict,\" \"seek,\" \"should,\" \"will,\" \"would,\" \"expect,\" \"objective,\" \"projection,\" \"forecast,\" \"goal,\" \"guidance,\" \"outlook,\" \"effort,\" \"target\" and other similar words can be used to identify forward-looking statements. However, the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dicts = parser_gpt4o.get_images(md_json_objs, download_path=\"data_images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyMMeTWhSec2",
        "outputId": "9b27f4b4-cb1a-4590-bc29-c68aad6e290b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Image for page 1: [{'name': 'page_1.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 2: [{'name': 'page_2.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 3: [{'name': 'page_3.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 4: [{'name': 'page_4.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 5: [{'name': 'page_5.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 6: [{'name': 'page_6.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 7: [{'name': 'page_7.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 8: [{'name': 'page_8.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 9: [{'name': 'page_9.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 10: [{'name': 'page_10.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 11: [{'name': 'page_11.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 12: [{'name': 'page_12.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 13: [{'name': 'page_13.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 14: [{'name': 'page_14.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 15: [{'name': 'page_15.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 16: [{'name': 'page_16.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 17: [{'name': 'page_17.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 18: [{'name': 'page_18.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 19: [{'name': 'page_19.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 20: [{'name': 'page_20.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 21: [{'name': 'page_21.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 22: [{'name': 'page_22.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 23: [{'name': 'page_23.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 24: [{'name': 'page_24.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 25: [{'name': 'page_25.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 26: [{'name': 'page_26.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 27: [{'name': 'page_27.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 28: [{'name': 'page_28.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 29: [{'name': 'page_29.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 30: [{'name': 'page_30.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 31: [{'name': 'page_31.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 32: [{'name': 'page_32.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 33: [{'name': 'page_33.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 34: [{'name': 'page_34.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 35: [{'name': 'page_35.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 36: [{'name': 'page_36.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 37: [{'name': 'page_37.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 38: [{'name': 'page_38.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 39: [{'name': 'page_39.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 40: [{'name': 'page_40.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 41: [{'name': 'page_41.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 42: [{'name': 'page_42.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 43: [{'name': 'page_43.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 44: [{'name': 'page_44.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 45: [{'name': 'page_45.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 46: [{'name': 'page_46.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 47: [{'name': 'page_47.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 48: [{'name': 'page_48.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 49: [{'name': 'page_49.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 50: [{'name': 'page_50.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 51: [{'name': 'page_51.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 52: [{'name': 'page_52.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 53: [{'name': 'page_53.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 54: [{'name': 'page_54.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 55: [{'name': 'page_55.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 56: [{'name': 'page_56.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 57: [{'name': 'page_57.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 58: [{'name': 'page_58.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 59: [{'name': 'page_59.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 60: [{'name': 'page_60.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 61: [{'name': 'page_61.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n",
            "> Image for page 62: [{'name': 'page_62.jpg', 'height': 0, 'width': 0, 'x': 0, 'y': 0, 'type': 'full_page_screenshot'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta linia kodu wyodrębnia obrazy z przetworzonego dokumentu PDF:\n",
        "\n",
        "`parser_gpt4o.get_images(md_json_objs, download_path=\"data_images\")`\n",
        "- Używa parsera w trybie GPT-4 do wyciągnięcia obrazów\n",
        "- Przyjmuje wcześniej utworzone obiekty JSON (`md_json_objs`)\n",
        "- Zapisuje znalezione obrazy w katalogu \"data_images\"\n",
        "- Zwraca słownik z informacjami o wyodrębnionych obrazach, który zostaje zapisany w zmiennej `image_dicts`\n",
        "\n",
        "Funkcja ta umożliwia zachowanie zarówno tekstu jak i obrazów z oryginalnego PDF-a, co jest kluczowe dla późniejszego przetwarzania multimodalnego."
      ],
      "metadata": {
        "id": "qaFf-2oLEjTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal index"
      ],
      "metadata": {
        "id": "aU9a_R17Sglq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_nodes = get_text_nodes(docs_text, image_dir=\"data_images\", json_dicts=md_json_list)"
      ],
      "metadata": {
        "id": "lM8dZRfEShtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta linia tworzy węzły tekstowe łącząc trzy źródła danych:\n",
        "\n",
        "`docs_text` - zawartość tekstowa z PDF-a\n",
        "`image_dir=\"data_images\"` - katalog z wyodrębnionymi obrazami\n",
        "`json_dicts=md_json_list` - lista stron w formacie Markdown\n",
        "\n",
        "Funkcja `get_text_nodes`:\n",
        "- Łączy tekst, obrazy i znaczniki Markdown w węzły\n",
        "- Dla każdej części dokumentu tworzy węzeł zawierający:\n",
        "  - Numer strony\n",
        "  - Ścieżkę do odpowiadającego obrazu strony\n",
        "  - Tekst w formacie Markdown\n",
        "  - Oryginalny tekst\n",
        "- Zachowuje odpowiednią kolejność stron\n",
        "\n",
        "Wynik jest zapisywany w zmiennej `text_nodes`, która będzie używana do dalszego przetwarzania i wyszukiwania informacji."
      ],
      "metadata": {
        "id": "SKHNAp8WFAky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if not os.path.exists(\"storage_nodes\"):\n",
        "    index = VectorStoreIndex(text_nodes, embed_model=embed_model)\n",
        "    # save index to disk\n",
        "    index.set_index_id(\"vector_index\")\n",
        "    index.storage_context.persist(\"./storage_nodes\")\n",
        "else:\n",
        "    # rebuild storage context\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=\"storage_nodes\")\n",
        "    # load index\n",
        "    index = load_index_from_storage(storage_context, index_id=\"vector_index\")\n",
        "\n",
        "retriever = index.as_retriever()"
      ],
      "metadata": {
        "id": "6tSlfGSsTXVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod zarządza indeksem wektorowym dokumentów:\n",
        "\n",
        "Jeśli katalog \"storage_nodes\" nie istnieje:\n",
        "- Tworzy nowy indeks wektorowy z węzłów tekstowych\n",
        "- Używa wcześniej skonfigurowanego modelu do embedingów\n",
        "- Ustawia identyfikator indeksu jako \"vector_index\"\n",
        "- Zapisuje indeks na dysku w katalogu \"./storage_nodes\"\n",
        "\n",
        "Jeśli katalog istnieje:\n",
        "- Odtwarza kontekst przechowywania z istniejącego katalogu\n",
        "- Wczytuje zapisany indeks o identyfikatorze \"vector_index\"\n",
        "\n",
        "Na końcu tworzy obiekt `retriever` z indeksu, który będzie służył do wyszukiwania odpowiednich fragmentów dokumentów podczas odpowiadania na zapytania.\n",
        "\n",
        "Takie podejście pozwala zaoszczędzić czas i zasoby - raz utworzony indeks jest przechowywany i może być wielokrotnie używany zamiast tworzenia go od nowa przy każdym uruchomieniu."
      ],
      "metadata": {
        "id": "U9cbpcspIRF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal query engine"
      ],
      "metadata": {
        "id": "8E3kmrAAUI-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "gpt_4o = OpenAIMultiModal(model = CFG.model1, max_new_tokens=4096)\n",
        "\n",
        "QA_PROMPT_TMPL = \"\"\"\\\n",
        "Below we give parsed text from slides in two different formats, as well as the image.\n",
        "\n",
        "We parse the text in both 'markdown' mode as well as 'raw text' mode. Markdown mode attempts \\\n",
        "to convert relevant diagrams into tables, whereas raw text tries to maintain the rough spatial \\\n",
        "layout of the text.\n",
        "\n",
        "Use the image information first and foremost. ONLY use the text/markdown information\n",
        "if you can't understand the image.\n",
        "\n",
        "---------------------\n",
        "{context_str}\n",
        "---------------------\n",
        "Given the context information and not prior knowledge, answer the query. Explain whether you got the answer\n",
        "from the parsed markdown or raw text or image, and if there's discrepancies, and your reasoning for the final answer.\n",
        "\n",
        "Query: {query_str}\n",
        "Answer: \"\"\"\n",
        "\n",
        "QA_PROMPT = PromptTemplate(QA_PROMPT_TMPL)"
      ],
      "metadata": {
        "id": "2mkCa__MUKpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod konfiguruje komponenty do generowania odpowiedzi na pytania:\n",
        "\n",
        "1. Konfiguracja modelu multimodalnego:\n",
        "```python\n",
        "gpt_4o = OpenAIMultiModal(model = CFG.model1, max_new_tokens=4096)\n",
        "```\n",
        "- Tworzy instancję modelu obsługującego tekst i obrazy\n",
        "- Ustawia limit 4096 nowych tokenów w odpowiedzi\n",
        "\n",
        "2. Definicja szablonu promptu (`QA_PROMPT_TMPL`):\n",
        "- Informuje model, że otrzyma:\n",
        "  - Tekst w dwóch formatach (Markdown i surowy tekst)\n",
        "  - Powiązane obrazy\n",
        "- Wyjaśnia różnice między formatami:\n",
        "  - Markdown próbuje przekształcać diagramy w tabele\n",
        "  - Surowy tekst zachowuje układ przestrzenny\n",
        "- Instruuje model aby:\n",
        "  - Priorytetowo traktował informacje z obrazów\n",
        "  - Używał tekstu tylko gdy obraz jest niejasny\n",
        "  - Wyjaśnił źródło informacji (Markdown/tekst/obraz)\n",
        "  - Wskazał ewentualne rozbieżności\n",
        "  - Uzasadnił finalną odpowiedź\n",
        "\n",
        "3. Tworzenie obiektu szablonu:\n",
        "```python\n",
        "QA_PROMPT = PromptTemplate(QA_PROMPT_TMPL)\n",
        "```\n",
        "Przekształca szablon tekstowy w obiekt, który będzie używany do generowania promptów."
      ],
      "metadata": {
        "id": "ecuLclGvIYGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = MultimodalQueryEngine(\n",
        "    retriever=index.as_retriever(similarity_top_k=9), multi_modal_llm=gpt_4o\n",
        ")"
      ],
      "metadata": {
        "id": "sKugmOY8UldO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod tworzy silnik do obsługi zapytań multimodalnych:\n",
        "\n",
        "- Używa wcześniej zdefiniowanej klasy `MultimodalQueryEngine`\n",
        "- Konfiguruje go z dwoma głównymi komponentami:\n",
        "  1. Retriever (wyszukiwarka) z indeksu:\n",
        "     - Parametr `similarity_top_k=9` oznacza, że będzie zwracać 9 najbardziej podobnych fragmentów do zapytania\n",
        "  2. Model multimodalny GPT-4 (`gpt_4o`) do analizy tekstu i obrazów\n",
        "\n",
        "Utworzony `query_engine` będzie:\n",
        "- Wyszukiwać odpowiednie fragmenty dokumentu na podstawie zapytania\n",
        "- Analizować powiązane obrazy\n",
        "- Generować odpowiedzi uwzględniające zarówno tekst jak i zawartość wizualną"
      ],
      "metadata": {
        "id": "hsSoSnTZIwPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_nodes = get_nodes(docs_text)"
      ],
      "metadata": {
        "id": "LlUXOKgJVSG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta linia wykonuje uproszczone przetwarzanie dokumentów tekstowych (`docs_text`) na węzły.\n",
        "\n",
        "W przeciwieństwie do wcześniej użytej funkcji `get_text_nodes`, funkcja `get_nodes`:\n",
        "- Pomija powiązania z obrazami\n",
        "- Nie uwzględnia znaczników Markdown\n",
        "- Zachowuje oryginalny tekst w węźle zamiast w metadanych\n",
        "- Kopiuje wszystkie metadane z dokumentu źródłowego do każdego węzła\n",
        "- Dzieli tekst używając separatora \"\\n---\\n\"\n",
        "\n",
        "Te podstawowe węzły mogą służyć jako alternatywne źródło danych dla zapytań, które nie wymagają analizy obrazów."
      ],
      "metadata": {
        "id": "qW-bLHj5IxfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_index = VectorStoreIndex(base_nodes, embed_model=embed_model)"
      ],
      "metadata": {
        "id": "D3HfqC8yVZfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta linia tworzy nowy indeks wektorowy:\n",
        "- Używa podstawowych węzłów tekstowych (`base_nodes`)\n",
        "- Wykorzystuje wcześniej skonfigurowany model do tworzenia embedingów (`embed_model`)\n",
        "- Nie zawiera informacji o obrazach ani znacznikach Markdown\n",
        "\n",
        "Jest to uproszczona wersja wcześniejszego indeksu, która może być używana do szybszego wyszukiwania gdy nie potrzebujemy analizy wizualnej.\n",
        "\n",
        "Ten dodatkowy indeks może być przydatny do:\n",
        "- Prostych zapytań tekstowych\n",
        "- Porównywania wyników z pełnym indeksem multimodalnym\n",
        "- Sytuacji gdy priorytetem jest szybkość, a nie pełna analiza dokumentu"
      ],
      "metadata": {
        "id": "6bX5noO8Ix6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_query_engine = base_index.as_query_engine(llm=llm, similarity_top_k=9)"
      ],
      "metadata": {
        "id": "EWbmM2gxVavU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta linia tworzy podstawowy silnik zapytań:\n",
        "- Używa wcześniej utworzonego indeksu (`base_index`)\n",
        "- Konfiguruje go z podstawowym modelem językowym (`llm`)\n",
        "- Ustawia parametr `similarity_top_k=9`, co oznacza że będzie zwracać 9 najbardziej podobnych fragmentów\n",
        "\n",
        "Jest to prostsza wersja silnika zapytań w porównaniu do `query_engine`:\n",
        "- Obsługuje tylko tekst (bez obrazów)\n",
        "- Używa standardowego modelu językowego zamiast multimodalnego\n",
        "- Jest szybszy w działaniu\n",
        "- Nadaje się do prostszych zapytań niewymagających analizy wizualnej"
      ],
      "metadata": {
        "id": "TzFc_DLpIyYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal agent"
      ],
      "metadata": {
        "id": "3L_9eBob7SAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=query_engine,\n",
        "    name=\"vector_tool\",\n",
        "    description=(\n",
        "        \"Useful for retrieving specific context from the data. Do NOT select if question asks for a summary of the data.\"\n",
        "    ),\n",
        ")\n",
        "agent = FunctionCallingAgentWorker.from_tools(\n",
        "    [vector_tool], llm=llm, verbose=True\n",
        ").as_agent()"
      ],
      "metadata": {
        "id": "lc-WHC_v7THu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten kod tworzy system agenta z narzędziami do odpowiadania na pytania:\n",
        "\n",
        "1. Tworzy narzędzie wyszukiwania (`vector_tool`):\n",
        "- Używa silnika zapytań multimodalnych (`query_engine`)\n",
        "- Nadaje mu nazwę \"vector_tool\"\n",
        "- Określa opis wyjaśniający, że narzędzie jest przydatne do wyszukiwania konkretnych informacji, ale nie do tworzenia podsumowań\n",
        "\n",
        "2. Tworzy agenta (`agent`):\n",
        "- Inicjalizuje go z listą narzędzi (na razie tylko `vector_tool`)\n",
        "- Używa wcześniej zdefiniowanego modelu językowego (`llm`)\n",
        "- Włącza tryb szczegółowy (`verbose=True`), który będzie pokazywał proces podejmowania decyzji\n",
        "- Konwertuje na interfejs agenta za pomocą `as_agent()`\n",
        "\n",
        "Ten agent może samodzielnie decydować, kiedy użyć narzędzia wektorowego do znalezienia odpowiednich informacji w dokumentach."
      ],
      "metadata": {
        "id": "kxfRUD9CJt8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a similar agent for the baseline\n",
        "base_vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=base_query_engine,\n",
        "    name=\"vector_tool\",\n",
        "    description=(\n",
        "        \"Useful for retrieving specific context from the data. Do NOT select if question asks for a summary of the data.\"\n",
        "    ),\n",
        ")\n",
        "base_agent = FunctionCallingAgentWorker.from_tools(\n",
        "    [base_vector_tool], llm=llm, verbose=True\n",
        ").as_agent()"
      ],
      "metadata": {
        "id": "jqZ5Lcml7YRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten fragment tworzy analogiczny system agenta dla podstawowej wersji wyszukiwania:\n",
        "\n",
        "1. Tworzy narzędzie `base_vector_tool`:\n",
        "- Oparte na podstawowym silniku zapytań (`base_query_engine`)\n",
        "- Ma taką samą nazwę i opis jak poprzednie narzędzie\n",
        "- Działa tylko na tekście, bez obsługi obrazów\n",
        "\n",
        "2. Tworzy agenta `base_agent`:\n",
        "- Inicjalizuje go z podstawowym narzędziem wektorowym\n",
        "- Używa tego samego modelu językowego\n",
        "- Ma włączony tryb szczegółowy\n",
        "\n",
        "Ten drugi agent służy jako punkt odniesienia - pozwala porównać wyniki wyszukiwania z wersją multimodalną i ocenić, czy dodatkowe informacje z obrazów poprawiają jakość odpowiedzi."
      ],
      "metadata": {
        "id": "dWBUd1peJ7dw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "USKwVJMo7fml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = (\n",
        "    \"Where does the company have production?\"\n",
        ")"
      ],
      "metadata": {
        "id": "gYWFMzn27ePL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_response = base_agent.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0D5tHl67-HN",
        "outputId": "e31bf9ab-6997-42b2-d11a-eead203a1dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Where does the company have production?\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool with args: {\"input\": \"production locations of the company\"}\n",
            "=== Function Output ===\n",
            "The company has production locations in the Lower 48 states, Alaska, Canada, Norway, Libya, Malaysia, China, Qatar, and the Asia Pacific region.\n",
            "=== LLM Response ===\n",
            "The company has production locations in the Lower 48 states, Alaska, Canada, Norway, Libya, Malaysia, China, Qatar, and the Asia Pacific region.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = agent.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rxCg-xu7-2L",
        "outputId": "1972627f-613f-4262-f520-9a7d71f2d736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Where does the company have production?\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool with args: {\"input\": \"production locations of the company\"}\n",
            "=== Function Output ===\n",
            "The production locations of ConocoPhillips, as seen in the images, include:\n",
            "\n",
            "- **Lower 48 (U.S.)**: Permian, Eagle Ford, Bakken\n",
            "- **Alaska**\n",
            "- **Canada**: Montney, Surmont\n",
            "- **EMENA**: Norway, Libya, Qatar\n",
            "- **Asia Pacific**: APLNG, Malaysia, China\n",
            "\n",
            "This information was derived from the images provided, which show maps and lists of production areas. The parsed text also supports this information, listing similar locations. There are no discrepancies between the image and the parsed text regarding the production locations.\n",
            "=== LLM Response ===\n",
            "The company has production in the following locations:\n",
            "\n",
            "- **Lower 48 (U.S.)**: Permian, Eagle Ford, Bakken\n",
            "- **Alaska**\n",
            "- **Canada**: Montney, Surmont\n",
            "- **EMENA**: Norway, Libya, Qatar\n",
            "- **Asia Pacific**: APLNG, Malaysia, China\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppr(str(base_response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJlOnln5-jr5",
        "outputId": "5c1c7ca5-3468-4dd0-e9e4-9556d0bf3b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The company has production locations in the Lower 48 states, Alaska, Canada, '\n",
            " 'Norway, Libya, Malaysia, China, Qatar, and the Asia Pacific region.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppr(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRjZvJD7-mbh",
        "outputId": "e5cffe81-dc9d-4ca1-b311-7ef7bb78dfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The company has production in the following locations:\\n'\n",
            " '\\n'\n",
            " '- **Lower 48 (U.S.)**: Permian, Eagle Ford, Bakken\\n'\n",
            " '- **Alaska**\\n'\n",
            " '- **Canada**: Montney, Surmont\\n'\n",
            " '- **EMENA**: Norway, Libya, Qatar\\n'\n",
            " '- **Asia Pacific**: APLNG, Malaysia, China')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppr(base_response.source_nodes[7].get_content(metadata_mode=\"all\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3qgNTsB_BME",
        "outputId": "af2a0d5e-9b03-4bd6-a988-bd9c902844a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Secondary Investment Criteria Reinforce Resilient; Durable Returns\\n'\n",
            " '                                Investment '\n",
            " 'Criteria                               Balanced, Diversified, Disciplined '\n",
            " 'Production Growth\\n'\n",
            " '                                                                                   '\n",
            " 'Production Mixl\\n'\n",
            " '    '\n",
            " '8                                                                              '\n",
            " 'Oil ~55%      NGL ~15%       North American Gas ~15%    International Gas ~ '\n",
            " '15%\\n'\n",
            " '                                                                                                                    '\n",
            " 'Production (MBOED)\\n'\n",
            " '    [                   Disciplined                               Cost '\n",
            " 'of                     ~4-5%\\n'\n",
            " '                  Reinvestment Rate                               '\n",
            " 'Supply        2,500\\n'\n",
            " '                    Returns of capital                   Returns on '\n",
            " 'capital              ProductioncXer                                  LNG '\n",
            " 'CASmont\\n'\n",
            " '                                                                                '\n",
            " '2,000                                                     Conventional\\n'\n",
            " '                                                                                                                                          '\n",
            " '~3% CAGR\\n'\n",
            " '    8                   Balance of short-cycle; '\n",
            " 'flexible                        1,500\\n'\n",
            " '                     unconventional with longer-cycle,low-decline '\n",
            " 'conventional  1,000\\n'\n",
            " '   6                 Product mix and market exposurePredictable '\n",
            " 'execution         500                                                    '\n",
            " '(Lower 48 +\\n'\n",
            " '                                                                                                                                                    '\n",
            " 'Unconventional\\n'\n",
            " '                                                                                                                                          '\n",
            " '~6% CAGR       Montney)\\n'\n",
            " '                                                                                     '\n",
            " '2023E                                                                              '\n",
            " '2032\\n'\n",
            " '!Average anticipated production mix from 2023-2032; oil includes bitumen:\\n'\n",
            " ' Reinvestment rate is a non-GAAP measure defined in the '\n",
            " 'Appendix                                                                                            '\n",
            " 'ConocoPhillips 13')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppr(response.source_nodes[7].get_content(metadata_mode=\"all\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VViX6MX3_Cxz",
        "outputId": "713d4342-1eed-474d-dbfe-ee279c615c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('page_num: 15\\n'\n",
            " 'image_path: data_images/affd3516-6466-4de8-a372-fbc4f7d6342b-page_3.jpg\\n'\n",
            " 'parsed_text_markdown: # Strong Track Record of Active Portfolio Management\\n'\n",
            " '\\n'\n",
            " '| Year | Activity |\\n'\n",
            " '|------|----------|\\n'\n",
            " '| 2016 | Production: 1.6 MMBOED <br> Resource < $40/BBL WTI: ~10 BBOE <br> '\n",
            " 'Average Cost of Supply: < $40/BBL WTI <br> Resource Life: >18 years <br> '\n",
            " 'Emissions Intensity: ~39 kg CO₂e/BOE |\\n'\n",
            " '| 2017 | San Juan Exit <br> Canada Cenovus Transaction |\\n'\n",
            " '| 2018 | WNS and GKA Working Interest Consolidations |\\n'\n",
            " '| 2019 | U.K. Exit |\\n'\n",
            " '| 2020 | Montney Acreage Acquisition |\\n'\n",
            " '| 2021 | Concho and Shell Permian Acquisitions <br> Niobrara and '\n",
            " 'Australia-West Exits |\\n'\n",
            " '| 2022 | APLNG Acquisition <br> Indonesia Exit <br> Production: 1.7 MMBOED '\n",
            " '<br> Resource < $40/BBL WTI: ~20 BBOE <br> Average Cost of Supply: ~ $32/BBL '\n",
            " 'WTI <br> Resource Life: >30 years <br> Emissions Intensity: ~22 kg CO₂e/BOE '\n",
            " '|\\n'\n",
            " '\\n'\n",
            " '**Cost of Supply Framework Drives Disciplined Transactions**\\n'\n",
            " '\\n'\n",
            " '~$25B of Both Acquisitions and Divestitures Since 2016²\\n'\n",
            " '\\n'\n",
            " '----\\n'\n",
            " '\\n'\n",
            " '¹Gross operated GHG emissions (Scope 1 and 2), 2022 is a preliminary '\n",
            " 'estimate.  \\n'\n",
            " '²Dispositions include contingent payment proceeds and sale of CVE shares.\\n'\n",
            " 'parsed_text: Strong Track Record of Active Portfolio Management\\n'\n",
            " '                                '\n",
            " '2016                                                                                                                                               '\n",
            " '2022\\n'\n",
            " '    Production            1.6 '\n",
            " 'MMBOED                                          WNS and '\n",
            " 'GKA                                    Montney            Concho '\n",
            " 'and                  1.7 MMBOED\\n'\n",
            " '                                                                             '\n",
            " 'Working Interest                                 Acreage          Shell '\n",
            " 'Permian     APLNG\\n'\n",
            " '                                                                              '\n",
            " 'Consolidations                                Acquisition          '\n",
            " 'Acquisitions  Acquisition\\n'\n",
            " '     Resource              ~10 '\n",
            " 'BBOE                                                                                                                                         '\n",
            " '~20 BBOE\\n'\n",
            " '  <S40/BBL WTI\\n'\n",
            " '                                                                                   '\n",
            " '2018                                       '\n",
            " '2020                               2022\\n'\n",
            " '     Average                S40/BBL '\n",
            " 'WTI                                                                                                                                     '\n",
            " '~S32/BBL WTI\\n'\n",
            " ' Cost of Supply                                               '\n",
            " '2017                                       '\n",
            " '2019                                       2021\\n'\n",
            " '  Resource Life            >18 '\n",
            " 'years                                                                                                                                        '\n",
            " '>30 years\\n'\n",
            " '                                                          San Juan '\n",
            " 'Exit                                  U.K Exit         Niobrara '\n",
            " 'and                         Indonesia\\n'\n",
            " '    Emissions                                          Canada '\n",
            " 'Cenovus                                                     '\n",
            " 'Australia-West                            Exit\\n'\n",
            " '     Intensityl            ~39 kg COze/BOE                  '\n",
            " 'Transaction                                                         '\n",
            " 'Exits                                       ~22 kg COze/BOE\\n'\n",
            " '                                                      Cost of Supply '\n",
            " 'Framework Drives Disciplined Transactions\\n'\n",
            " '                                                       $25B of Both '\n",
            " 'Acquisitions and Divestitures Since 20162\\n'\n",
            " '1Gross operated GHG emissions (Scopeand 2), 2022 is a preliminary estimate. '\n",
            " '2Dispositions include contingent payment proceeds and sale of CVE '\n",
            " 'shares                                ConocoPhillips  15')\n"
          ]
        }
      ]
    }
  ]
}